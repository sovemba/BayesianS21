<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lecture 18 Metropolis-Hastings | Bayesian Statistics lecture notes</title>
  <meta name="description" content="Lecture 18 Metropolis-Hastings | Bayesian Statistics lecture notes" />
  <meta name="generator" content="bookdown 0.22.2 and GitBook 2.6.7" />

  <meta property="og:title" content="Lecture 18 Metropolis-Hastings | Bayesian Statistics lecture notes" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lecture 18 Metropolis-Hastings | Bayesian Statistics lecture notes" />
  
  
  

<meta name="author" content="Chisom Onyishi" />


<meta name="date" content="2021-06-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="generalized-linear-models-the-metropolis-algorithm.html"/>
<link rel="next" href="linear-mixed-effects-models-aka-hierarchical-linear-models.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Belief and Probability</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#example"><i class="fa fa-check"></i><b>1.1</b> Example:</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#random-variables"><i class="fa fa-check"></i><b>1.2</b> Random Variables</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#binomial"><i class="fa fa-check"></i><b>1.3</b> Binomial distribution</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#poisson"><i class="fa fa-check"></i><b>1.4</b> Poisson distribution</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#continuous-random-variables"><i class="fa fa-check"></i><b>1.5</b> Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="index.html"><a href="index.html#example-normalmu-10.75-sigma0.8"><i class="fa fa-check"></i><b>1.5.1</b> Example: Normal(<span class="math inline">\(\mu = 10.75, \sigma=0.8\)</span>)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="exchangeability.html"><a href="exchangeability.html"><i class="fa fa-check"></i><b>2</b> Exchangeability</a>
<ul>
<li class="chapter" data-level="2.1" data-path="exchangeability.html"><a href="exchangeability.html#discrete-joint-distributions"><i class="fa fa-check"></i><b>2.1</b> Discrete joint distributions</a></li>
<li class="chapter" data-level="2.2" data-path="exchangeability.html"><a href="exchangeability.html#bayesrule"><i class="fa fa-check"></i><b>2.2</b> Bayes’ rule and parameter estimation</a></li>
<li class="chapter" data-level="2.3" data-path="exchangeability.html"><a href="exchangeability.html#independent-random-variables"><i class="fa fa-check"></i><b>2.3</b> Independent random variables</a></li>
<li class="chapter" data-level="2.4" data-path="exchangeability.html"><a href="exchangeability.html#exchangeability-1"><i class="fa fa-check"></i><b>2.4</b> Exchangeability</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="binomial-1.html"><a href="binomial-1.html"><i class="fa fa-check"></i><b>3</b> Binomial</a>
<ul>
<li class="chapter" data-level="3.1" data-path="binomial-1.html"><a href="binomial-1.html#example---exchangeable-binary-data"><i class="fa fa-check"></i><b>3.1</b> Example - Exchangeable binary data</a></li>
<li class="chapter" data-level="3.2" data-path="binomial-1.html"><a href="binomial-1.html#the-beta-distribution"><i class="fa fa-check"></i><b>3.2</b> The beta distribution</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="binomial-1.html"><a href="binomial-1.html#properties-of-the-beta-distribution"><i class="fa fa-check"></i><b>3.2.1</b> Properties of the beta distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="binomial-1.html"><a href="binomial-1.html#binomial-distribution"><i class="fa fa-check"></i><b>3.3</b> Binomial distribution</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="binomial-1.html"><a href="binomial-1.html#posterior-inference-for-a-binomial-sampling-model"><i class="fa fa-check"></i><b>3.3.1</b> Posterior inference for a binomial sampling model</a></li>
<li class="chapter" data-level="3.3.2" data-path="binomial-1.html"><a href="binomial-1.html#conjugacy"><i class="fa fa-check"></i><b>3.3.2</b> Conjugacy</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="binomial-1.html"><a href="binomial-1.html#combining-information"><i class="fa fa-check"></i><b>3.4</b> Combining information</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="binomial-1.html"><a href="binomial-1.html#example-1"><i class="fa fa-check"></i><b>3.4.1</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="binomial-1.html"><a href="binomial-1.html#prediction"><i class="fa fa-check"></i><b>3.5</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="CI.html"><a href="CI.html"><i class="fa fa-check"></i><b>4</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="4.1" data-path="CI.html"><a href="CI.html#confidence-intervals"><i class="fa fa-check"></i><b>4.1</b> Confidence Intervals</a></li>
<li class="chapter" data-level="4.2" data-path="CI.html"><a href="CI.html#how-do-we-compute-intervals"><i class="fa fa-check"></i><b>4.2</b> How do we compute intervals?</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="CI.html"><a href="CI.html#example-2"><i class="fa fa-check"></i><b>4.2.1</b> Example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="poisson-model.html"><a href="poisson-model.html"><i class="fa fa-check"></i><b>5</b> Poisson model</a>
<ul>
<li class="chapter" data-level="5.1" data-path="poisson-model.html"><a href="poisson-model.html#posterior-inference-for-the-poisson-model"><i class="fa fa-check"></i><b>5.1</b> Posterior inference for the Poisson model</a></li>
<li class="chapter" data-level="5.2" data-path="poisson-model.html"><a href="poisson-model.html#posterior-predictive-distribution"><i class="fa fa-check"></i><b>5.2</b> Posterior predictive distribution</a></li>
<li class="chapter" data-level="5.3" data-path="poisson-model.html"><a href="poisson-model.html#example-birth-rates"><i class="fa fa-check"></i><b>5.3</b> Example: Birth rates</a></li>
<li class="chapter" data-level="5.4" data-path="poisson-model.html"><a href="poisson-model.html#explaining-the-parameters-of-the-gamma-distribution"><i class="fa fa-check"></i><b>5.4</b> Explaining the parameters of the gamma distribution</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="monte-carlo.html"><a href="monte-carlo.html"><i class="fa fa-check"></i><b>6</b> Monte Carlo</a>
<ul>
<li class="chapter" data-level="6.1" data-path="monte-carlo.html"><a href="monte-carlo.html#example-birth-rate"><i class="fa fa-check"></i><b>6.1</b> Example: birth rate</a></li>
<li class="chapter" data-level="6.2" data-path="monte-carlo.html"><a href="monte-carlo.html#the-monte-carlo-method"><i class="fa fa-check"></i><b>6.2</b> The Monte Carlo method</a></li>
<li class="chapter" data-level="6.3" data-path="monte-carlo.html"><a href="monte-carlo.html#example-numerical-evaluation"><i class="fa fa-check"></i><b>6.3</b> Example: Numerical evaluation</a></li>
<li class="chapter" data-level="6.4" data-path="monte-carlo.html"><a href="monte-carlo.html#posterior-inference-for-arbitrary-functions"><i class="fa fa-check"></i><b>6.4</b> Posterior inference for arbitrary functions</a></li>
<li class="chapter" data-level="6.5" data-path="monte-carlo.html"><a href="monte-carlo.html#example-log-odds"><i class="fa fa-check"></i><b>6.5</b> Example: Log-odds</a></li>
<li class="chapter" data-level="6.6" data-path="monte-carlo.html"><a href="monte-carlo.html#example-functions-of-two-parameters"><i class="fa fa-check"></i><b>6.6</b> Example: Functions of two parameters</a></li>
<li class="chapter" data-level="6.7" data-path="monte-carlo.html"><a href="monte-carlo.html#how-many-monte-carlo-samples-are-needed"><i class="fa fa-check"></i><b>6.7</b> How many Monte Carlo samples are needed?</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="predictive.html"><a href="predictive.html"><i class="fa fa-check"></i><b>7</b> Predictive</a>
<ul>
<li class="chapter" data-level="7.1" data-path="predictive.html"><a href="predictive.html#sampling-for-predictive-distribution"><i class="fa fa-check"></i><b>7.1</b> Sampling for predictive distribution</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="predictive.html"><a href="predictive.html#example-birth-rate-1"><i class="fa fa-check"></i><b>7.1.1</b> Example: birth rate</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="predictive.html"><a href="predictive.html#example-let-d-tilde-y_1---tilde-y_2"><i class="fa fa-check"></i><b>7.2</b> Example: Let <span class="math inline">\(D = \tilde Y_1 - \tilde Y_2\)</span></a></li>
<li class="chapter" data-level="7.3" data-path="predictive.html"><a href="predictive.html#posterior-predictive-model-checking"><i class="fa fa-check"></i><b>7.3</b> Posterior predictive model checking</a></li>
<li class="chapter" data-level="7.4" data-path="predictive.html"><a href="predictive.html#posterior-predictive-model-checking-1"><i class="fa fa-check"></i><b>7.4</b> Posterior predictive model checking</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="normal-mean.html"><a href="normal-mean.html"><i class="fa fa-check"></i><b>8</b> Normal Mean</a>
<ul>
<li class="chapter" data-level="8.1" data-path="normal-mean.html"><a href="normal-mean.html#example-womens-height"><i class="fa fa-check"></i><b>8.1</b> Example: women’s height</a></li>
<li class="chapter" data-level="8.2" data-path="normal-mean.html"><a href="normal-mean.html#inference-for-the-mean-conditional-on-the-variance"><i class="fa fa-check"></i><b>8.2</b> Inference for the mean, conditional on the variance</a></li>
<li class="chapter" data-level="8.3" data-path="normal-mean.html"><a href="normal-mean.html#prediction-1"><i class="fa fa-check"></i><b>8.3</b> Prediction</a></li>
<li class="chapter" data-level="8.4" data-path="normal-mean.html"><a href="normal-mean.html#example-midge-wing-length"><i class="fa fa-check"></i><b>8.4</b> Example: Midge wing length</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="joint-inference-for-normal-mean-and-variance.html"><a href="joint-inference-for-normal-mean-and-variance.html"><i class="fa fa-check"></i><b>9</b> Joint inference for Normal mean and variance</a>
<ul>
<li class="chapter" data-level="9.1" data-path="joint-inference-for-normal-mean-and-variance.html"><a href="joint-inference-for-normal-mean-and-variance.html#marginal-posterior-of-sigma2"><i class="fa fa-check"></i><b>9.1</b> Marginal posterior of <span class="math inline">\(\sigma^2\)</span></a></li>
<li class="chapter" data-level="9.2" data-path="joint-inference-for-normal-mean-and-variance.html"><a href="joint-inference-for-normal-mean-and-variance.html#example-midge-wing-length-1"><i class="fa fa-check"></i><b>9.2</b> Example: Midge wing length</a></li>
<li class="chapter" data-level="9.3" data-path="joint-inference-for-normal-mean-and-variance.html"><a href="joint-inference-for-normal-mean-and-variance.html#monte-carlo-sampling"><i class="fa fa-check"></i><b>9.3</b> Monte Carlo sampling</a></li>
<li class="chapter" data-level="9.4" data-path="joint-inference-for-normal-mean-and-variance.html"><a href="joint-inference-for-normal-mean-and-variance.html#summary-of-normal-formulas"><i class="fa fa-check"></i><b>9.4</b> Summary of Normal formulas</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="gibbs-sampler.html"><a href="gibbs-sampler.html"><i class="fa fa-check"></i><b>10</b> Gibbs sampler</a>
<ul>
<li class="chapter" data-level="10.1" data-path="gibbs-sampler.html"><a href="gibbs-sampler.html#review-of-conjugate-prior-for-normal-model"><i class="fa fa-check"></i><b>10.1</b> Review of conjugate prior for normal model</a></li>
<li class="chapter" data-level="10.2" data-path="gibbs-sampler.html"><a href="gibbs-sampler.html#a-semiconjugate-prior-distribution"><i class="fa fa-check"></i><b>10.2</b> A semiconjugate prior distribution</a></li>
<li class="chapter" data-level="10.3" data-path="gibbs-sampler.html"><a href="gibbs-sampler.html#gibbs-sampling"><i class="fa fa-check"></i><b>10.3</b> Gibbs sampling</a></li>
<li class="chapter" data-level="10.4" data-path="gibbs-sampler.html"><a href="gibbs-sampler.html#example-midge-wing-length-2"><i class="fa fa-check"></i><b>10.4</b> Example: Midge wing length</a></li>
<li class="chapter" data-level="10.5" data-path="gibbs-sampler.html"><a href="gibbs-sampler.html#discrete-approximation-of-posterior-distribution"><i class="fa fa-check"></i><b>10.5</b> Discrete approximation of posterior distribution</a></li>
<li class="chapter" data-level="10.6" data-path="gibbs-sampler.html"><a href="gibbs-sampler.html#example-3"><i class="fa fa-check"></i><b>10.6</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html"><i class="fa fa-check"></i><b>11</b> MCMC diagnostics</a>
<ul>
<li class="chapter" data-level="11.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#the-gibbs-sampler"><i class="fa fa-check"></i><b>11.1</b> The Gibbs sampler</a></li>
<li class="chapter" data-level="11.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#distinguishing-estimation-from-approximation"><i class="fa fa-check"></i><b>11.2</b> Distinguishing estimation from approximation</a></li>
<li class="chapter" data-level="11.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#introduction-to-mcmc-diagnostics"><i class="fa fa-check"></i><b>11.3</b> Introduction to MCMC diagnostics</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#example-mixture-of-normal-densities"><i class="fa fa-check"></i><b>11.3.1</b> Example: mixture of normal densities</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#discussion"><i class="fa fa-check"></i><b>11.4</b> Discussion</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#how-does-autocorrelationslow-mixing-affect-our-mcmc-approximation"><i class="fa fa-check"></i><b>11.4.1</b> How does autocorrelation(slow mixing) affect our MCMC approximation?</a></li>
<li class="chapter" data-level="11.4.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#autocorrelation"><i class="fa fa-check"></i><b>11.4.2</b> Autocorrelation</a></li>
<li class="chapter" data-level="11.4.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#sample-autocorrelation-function"><i class="fa fa-check"></i><b>11.4.3</b> Sample autocorrelation function</a></li>
<li class="chapter" data-level="11.4.4" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#effective-sample-size"><i class="fa fa-check"></i><b>11.4.4</b> Effective sample size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="multivariate-normal.html"><a href="multivariate-normal.html"><i class="fa fa-check"></i><b>12</b> Multivariate Normal</a>
<ul>
<li class="chapter" data-level="12.1" data-path="multivariate-normal.html"><a href="multivariate-normal.html#example-reading-comprehension"><i class="fa fa-check"></i><b>12.1</b> Example: Reading comprehension</a></li>
<li class="chapter" data-level="12.2" data-path="multivariate-normal.html"><a href="multivariate-normal.html#the-multivariate-normal-density"><i class="fa fa-check"></i><b>12.2</b> The multivariate normal density</a></li>
<li class="chapter" data-level="12.3" data-path="multivariate-normal.html"><a href="multivariate-normal.html#a-semiconjugate-prior-distribution-for-the-mean"><i class="fa fa-check"></i><b>12.3</b> A semiconjugate prior distribution for the mean</a></li>
<li class="chapter" data-level="12.4" data-path="multivariate-normal.html"><a href="multivariate-normal.html#the-inverse-wishart-distribution"><i class="fa fa-check"></i><b>12.4</b> The inverse-Wishart distribution</a></li>
<li class="chapter" data-level="12.5" data-path="multivariate-normal.html"><a href="multivariate-normal.html#full-conditional-distribution-of-the-covariance-matrix"><i class="fa fa-check"></i><b>12.5</b> Full conditional distribution of the covariance matrix</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="group-comparisons.html"><a href="group-comparisons.html"><i class="fa fa-check"></i><b>13</b> Group comparisons</a>
<ul>
<li class="chapter" data-level="13.1" data-path="group-comparisons.html"><a href="group-comparisons.html#comparing-two-groups"><i class="fa fa-check"></i><b>13.1</b> Comparing two groups</a></li>
<li class="chapter" data-level="13.2" data-path="group-comparisons.html"><a href="group-comparisons.html#mathex1"><i class="fa fa-check"></i><b>13.2</b> Example: Math scores data</a></li>
<li class="chapter" data-level="13.3" data-path="group-comparisons.html"><a href="group-comparisons.html#bayesmodel"><i class="fa fa-check"></i><b>13.3</b> A Bayesian model</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="group-comparisons.html"><a href="group-comparisons.html#analysis-of-the-math-scores-data"><i class="fa fa-check"></i><b>13.3.1</b> Analysis of the math scores data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html"><i class="fa fa-check"></i><b>14</b> The hierarchical normal model</a>
<ul>
<li class="chapter" data-level="14.1" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#postinf"><i class="fa fa-check"></i><b>14.1</b> Posterior inference</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#full-conditional-distributions-of-mu-and-tau2"><i class="fa fa-check"></i><b>14.1.1</b> Full conditional distributions of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau^2\)</span></a></li>
<li class="chapter" data-level="14.1.2" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#full-conditional-of-theta_j"><i class="fa fa-check"></i><b>14.1.2</b> Full conditional of <span class="math inline">\(\theta_j\)</span></a></li>
<li class="chapter" data-level="14.1.3" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#full-conditional-of-sigma2"><i class="fa fa-check"></i><b>14.1.3</b> Full conditional of <span class="math inline">\(\sigma^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#mathex2"><i class="fa fa-check"></i><b>14.2</b> Example: Math scores in U.S. public schools</a></li>
<li class="chapter" data-level="14.3" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#posterior-approximation"><i class="fa fa-check"></i><b>14.3</b> Posterior approximation</a></li>
<li class="chapter" data-level="14.4" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#mcmc-diagnostics-1"><i class="fa fa-check"></i><b>14.4</b> MCMC diagnostics</a></li>
<li class="chapter" data-level="14.5" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#shrinkage"><i class="fa fa-check"></i><b>14.5</b> Shrinkage</a></li>
<li class="chapter" data-level="14.6" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#ranking-the-groups"><i class="fa fa-check"></i><b>14.6</b> Ranking the groups</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>15</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="15.1" data-path="linear-regression.html"><a href="linear-regression.html#example-oxygen-uptake"><i class="fa fa-check"></i><b>15.1</b> Example: Oxygen uptake</a></li>
<li class="chapter" data-level="15.2" data-path="linear-regression.html"><a href="linear-regression.html#least-squares-estimation"><i class="fa fa-check"></i><b>15.2</b> Least squares estimation</a></li>
<li class="chapter" data-level="15.3" data-path="linear-regression.html"><a href="linear-regression.html#least-squares-estimation-for-oxygen-uptake-data"><i class="fa fa-check"></i><b>15.3</b> Least squares estimation for oxygen uptake data</a></li>
<li class="chapter" data-level="15.4" data-path="linear-regression.html"><a href="linear-regression.html#bayesian-estimation-for-a-regression-model"><i class="fa fa-check"></i><b>15.4</b> Bayesian estimation for a regression model</a></li>
<li class="chapter" data-level="15.5" data-path="linear-regression.html"><a href="linear-regression.html#unit-information-prior"><i class="fa fa-check"></i><b>15.5</b> Unit information prior</a></li>
<li class="chapter" data-level="15.6" data-path="linear-regression.html"><a href="linear-regression.html#zellners-g-prior"><i class="fa fa-check"></i><b>15.6</b> Zellner’s <span class="math inline">\(g\)</span>-prior</a></li>
<li class="chapter" data-level="15.7" data-path="linear-regression.html"><a href="linear-regression.html#bayesian-analysis-using-invariant-g-prior"><i class="fa fa-check"></i><b>15.7</b> Bayesian analysis using invariant <span class="math inline">\(g\)</span>-prior</a></li>
<li class="chapter" data-level="15.8" data-path="linear-regression.html"><a href="linear-regression.html#bayesian-analysis-using-semiconjugate-prior"><i class="fa fa-check"></i><b>15.8</b> Bayesian analysis using semiconjugate prior</a>
<ul>
<li class="chapter" data-level="15.8.1" data-path="linear-regression.html"><a href="linear-regression.html#prediction-problem"><i class="fa fa-check"></i><b>15.8.1</b> Prediction problem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="model-selection.html"><a href="model-selection.html"><i class="fa fa-check"></i><b>16</b> Model Selection</a>
<ul>
<li class="chapter" data-level="16.1" data-path="model-selection.html"><a href="model-selection.html#review"><i class="fa fa-check"></i><b>16.1</b> Review</a></li>
<li class="chapter" data-level="16.2" data-path="model-selection.html"><a href="model-selection.html#bayesian-model-comparison"><i class="fa fa-check"></i><b>16.2</b> Bayesian model comparison</a></li>
<li class="chapter" data-level="16.3" data-path="model-selection.html"><a href="model-selection.html#example-oxygen-uptake-1"><i class="fa fa-check"></i><b>16.3</b> Example: Oxygen uptake</a></li>
<li class="chapter" data-level="16.4" data-path="model-selection.html"><a href="model-selection.html#gibbs-sampling-and-model-averaging"><i class="fa fa-check"></i><b>16.4</b> Gibbs sampling and model averaging</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html"><i class="fa fa-check"></i><b>17</b> Generalized Linear Models; the Metropolis Algorithm</a>
<ul>
<li class="chapter" data-level="17.1" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html#example-song-sparrow-reproductive-success"><i class="fa fa-check"></i><b>17.1</b> Example: Song sparrow reproductive success</a></li>
<li class="chapter" data-level="17.2" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html#sec:poisson"><i class="fa fa-check"></i><b>17.2</b> Poisson regression</a></li>
<li class="chapter" data-level="17.3" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html#logistic-regression"><i class="fa fa-check"></i><b>17.3</b> Logistic regression</a></li>
<li class="chapter" data-level="17.4" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html#posterior-approximations"><i class="fa fa-check"></i><b>17.4</b> Posterior approximations</a></li>
<li class="chapter" data-level="17.5" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html#the-metropolis-algorithm"><i class="fa fa-check"></i><b>17.5</b> The Metropolis algorithm</a></li>
<li class="chapter" data-level="17.6" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html#example-normal-distribution-with-known-variance"><i class="fa fa-check"></i><b>17.6</b> Example: Normal distribution with known variance</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html#output-of-metropolis-algorithm"><i class="fa fa-check"></i><b>17.6.1</b> Output of Metropolis Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html#the-metropolis-algorithm-for-poisson-regression-secmetpois"><i class="fa fa-check"></i><b>17.7</b> The Metropolis algorithm for Poisson regression {sec:metpois}</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="metropolis-hastings.html"><a href="metropolis-hastings.html"><i class="fa fa-check"></i><b>18</b> Metropolis-Hastings</a>
<ul>
<li class="chapter" data-level="18.1" data-path="metropolis-hastings.html"><a href="metropolis-hastings.html#why-does-the-metropolis-hastings-algorithm-work"><i class="fa fa-check"></i><b>18.1</b> Why does the Metropolis-Hastings algorithm work?</a></li>
<li class="chapter" data-level="18.2" data-path="metropolis-hastings.html"><a href="metropolis-hastings.html#combining-the-metropolis-and-gibbs-algorithms"><i class="fa fa-check"></i><b>18.2</b> Combining the Metropolis and Gibbs algorithms</a></li>
<li class="chapter" data-level="18.3" data-path="metropolis-hastings.html"><a href="metropolis-hastings.html#example-historical-co_2-and-temperature-data"><i class="fa fa-check"></i><b>18.3</b> Example: Historical CO<span class="math inline">\(_2\)</span> and temperature data</a></li>
<li class="chapter" data-level="18.4" data-path="metropolis-hastings.html"><a href="metropolis-hastings.html#a-regression-model-with-correlated-errors"><i class="fa fa-check"></i><b>18.4</b> A regression model with correlated errors</a></li>
<li class="chapter" data-level="18.5" data-path="metropolis-hastings.html"><a href="metropolis-hastings.html#analysis-of-the-ice-core-data"><i class="fa fa-check"></i><b>18.5</b> Analysis of the ice core data</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><i class="fa fa-check"></i><b>19</b> Linear Mixed-effects Models, aka, Hierarchical Linear Models</a>
<ul>
<li class="chapter" data-level="19.1" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html#hierarchical-model-review"><i class="fa fa-check"></i><b>19.1</b> Hierarchical model review</a></li>
<li class="chapter" data-level="19.2" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html#hierarchical-linear-regression-model-for-math-scores-data"><i class="fa fa-check"></i><b>19.2</b> Hierarchical linear regression model for math scores data</a></li>
<li class="chapter" data-level="19.3" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html#bayesian-hierarchical-linear-regression-model"><i class="fa fa-check"></i><b>19.3</b> Bayesian hierarchical linear regression model</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html#full-conditionals"><i class="fa fa-check"></i><b>19.3.1</b> Full conditionals</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html#bayesian-analysis-of-the-math-scores-data"><i class="fa fa-check"></i><b>19.4</b> Bayesian analysis of the math scores data</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html#mcmc-diagnostics-2"><i class="fa fa-check"></i><b>19.4.1</b> MCMC diagnostics</a></li>
<li class="chapter" data-level="19.4.2" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html#posterior-summaries"><i class="fa fa-check"></i><b>19.4.2</b> Posterior summaries</a></li>
<li class="chapter" data-level="19.4.3" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html#posterior-predictive-simulation"><i class="fa fa-check"></i><b>19.4.3</b> Posterior predictive simulation</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian Statistics lecture notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="metropolis-hastings" class="section level1" number="18">
<h1><span class="header-section-number">Lecture 18</span> Metropolis-Hastings</h1>
<p><tt>The following notes, mostly transcribed from Neath(0603,2021) lecture, summarize sections (10.4-10.5) of Hoff(2009).</tt></p>
<p>
 
</p>
<p>The Metropolis algorithm and, for that matter, the Gibbs sampler as well are both special cases of a more general MCMC algorithm Metropolis-Hastings.</p>
<div id="why-does-the-metropolis-hastings-algorithm-work" class="section level2" number="18.1">
<h2><span class="header-section-number">18.1</span> Why does the Metropolis-Hastings algorithm work?</h2>
<p>Notation switch! we’re not doing <span class="math inline">\(\theta\)</span> with <span class="math inline">\(p(\theta |\boldsymbol y)\)</span> as the target distribution. Now we’re doing generic <span class="math inline">\(x\)</span> as the variable and <span class="math inline">\(p_0(x)\)</span> as the target density.</p>
<p>Current state of chain is <span class="math inline">\(x^{(s)}\)</span></p>
<ol style="list-style-type: decimal">
<li><p>Draw proposal <span class="math inline">\(x^{*}\)</span> from <span class="math inline">\(J_{s}\left(x^{*} \mid x^{(s)}\right)\)</span>;</p></li>
<li><p>Compute the acceptance ratio
<span class="math display">\[
r=\frac{p_{0}\left(x^{*}\right)}{p_{0}\left(x^{(s)}\right)} \times \frac{J_{s}\left(x^{(s)} \mid x^{*}\right)}{J_{s}\left(x^{*} \mid x^{(s)}\right)}
\]</span></p></li>
<li><p>Sample <span class="math inline">\(u \sim \operatorname{uniform}(0,1)\)</span>. If <span class="math inline">\(u&lt;r\)</span> set <span class="math inline">\(x^{(s+1)}=x^{*}\)</span>, else set <span class="math inline">\(x^{(s+1)}=x^{(s)}\)</span>.</p></li>
</ol>
<p>The Hastings innovation that generalized the Metropolis algorithm is to not require that the jump proposal distribution be symmetric around <span class="math inline">\(\theta^{(s)}\)</span>. If it is then the second component of the acceptance ratio is 1.0. Because the jump proposal distribution need not be symmetric the acceptance ratio needs to be adjusted for not just the relative probability in the target distribution but the relative frequency of getting proposed. So <span class="math inline">\(\theta^*\)</span> is a value that is getting proposed a lot then we want to reduce the probability of it getting accepted.</p>
</div>
<div id="combining-the-metropolis-and-gibbs-algorithms" class="section level2" number="18.2">
<h2><span class="header-section-number">18.2</span> Combining the Metropolis and Gibbs algorithms</h2>
<p>Sometimes you have a model with lots of variables for some of them the conditional distribution takes a nice form. Yay! We can do Gibbs updates for those components. But for other variables, perhaps not so nice. Can’t do Gibbs. So do Gibbs updates for the components where full conditional has a nice solution and for the components where the full conditional does not have a nice solution do a Metropolis update.</p>
</div>
<div id="example-historical-co_2-and-temperature-data" class="section level2" number="18.3">
<h2><span class="header-section-number">18.3</span> Example: Historical CO<span class="math inline">\(_2\)</span> and temperature data</h2>
<p>Data set on historic earth temperatures and CO<span class="math inline">\(_2\)</span> levels over 100s of thousands of years. Two variables observed every 1000 years or so are temperature and CO<span class="math inline">\(_2\)</span> concentration. These will be our <span class="math inline">\(y\)</span>-variable and <span class="math inline">\(x\)</span>-variable respectively.</p>
<p>Here’s a time series plot of the data</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="metropolis-hastings.html#cb282-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(icecore);  <span class="fu">names</span>(icecore)</span></code></pre></div>
<pre><code>## [1] 200   3</code></pre>
<pre><code>## [1] &quot;year&quot; &quot;co2&quot;  &quot;tmp&quot;</code></pre>
<p>Time between consecutive measurements is approximately 2,000 years.</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="metropolis-hastings.html#cb285-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(icecore[,<span class="dv">1</span>], (icecore[,<span class="dv">3</span>]<span class="sc">-</span><span class="fu">mean</span>(icecore[,<span class="dv">3</span>]))<span class="sc">/</span><span class="fu">sd</span>(icecore[,<span class="dv">3</span>]) , </span>
<span id="cb285-2"><a href="metropolis-hastings.html#cb285-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">xlab=</span><span class="st">&quot;year&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;standardized measurement&quot;</span>, </span>
<span id="cb285-3"><a href="metropolis-hastings.html#cb285-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.75</span>, <span class="dv">3</span>))</span>
<span id="cb285-4"><a href="metropolis-hastings.html#cb285-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb285-5"><a href="metropolis-hastings.html#cb285-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(icecore[,<span class="dv">1</span>], (icecore[,<span class="dv">2</span>]<span class="sc">-</span><span class="fu">mean</span>(icecore[,<span class="dv">2</span>]))<span class="sc">/</span><span class="fu">sd</span>(icecore[,<span class="dv">2</span>]), </span>
<span id="cb285-6"><a href="metropolis-hastings.html#cb285-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span><span class="st">&quot;pink&quot;</span>)  </span>
<span id="cb285-7"><a href="metropolis-hastings.html#cb285-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb285-8"><a href="metropolis-hastings.html#cb285-8" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">inset=</span>.<span class="dv">05</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;black&quot;</span>,<span class="st">&quot;pink&quot;</span>), </span>
<span id="cb285-9"><a href="metropolis-hastings.html#cb285-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;tmp&quot;</span>, <span class="st">&quot;co2&quot;</span>) )</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-188"></span>
<img src="bayesianS21_files/figure-html/unnamed-chunk-188-1.png" alt="Time series plot of temperature and carbon dioxide" width="672" />
<p class="caption">
Figure 18.1: Time series plot of temperature and carbon dioxide
</p>
</div>
<p>-4e+05 means 400,000 years ago.</p>
<p>How do you put these two time series on the same axes? one for temperature (difference from current levels in degrees Celsius) and one for CO<span class="math inline">\(_2\)</span> in parts per million volume. You have to standardize!</p>
<p>The agreement between these two time series is quite close. The model we’re going to fit is a linear regression model with temperature as the response and CO<span class="math inline">\(_2\)</span> as the predictor.</p>
<p>Our model will say:</p>
<p>let <span class="math inline">\(x_t = co_2\)</span> at time <span class="math inline">\(t\)</span></p>
<p>let <span class="math inline">\(y_t =\)</span> temperature at time <span class="math inline">\(t\)</span>, <span class="math inline">\(t = 1, 2, …., 200\)</span>. Time is just acting as an index here since we have equally spaced measurements.</p>
<p>We’re gonna consider a regression model in which <span class="math inline">\(y_t = \beta_1 + \beta_2 x_t + \epsilon_t = \beta_1 + \beta_2 \texttt{co2}_t + \epsilon_t\)</span>. This is a regression model relating <span class="math inline">\(\texttt{temp}\)</span> to <span class="math inline">\(\texttt{co2}\)</span>. This relationship is summarized by a scatterplot</p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="metropolis-hastings.html#cb286-1" aria-hidden="true" tabindex="-1"></a><span class="co"># time is not reflected on this plot</span></span>
<span id="cb286-2"><a href="metropolis-hastings.html#cb286-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(icecore[,<span class="dv">2</span>], icecore[,<span class="dv">3</span>], </span>
<span id="cb286-3"><a href="metropolis-hastings.html#cb286-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab=</span><span class="fu">expression</span>(<span class="fu">paste</span>(CO[<span class="dv">2</span>], <span class="st">&quot;(ppmv)&quot;</span>)), </span>
<span id="cb286-4"><a href="metropolis-hastings.html#cb286-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab=</span><span class="st">&quot;temperature difference (deg C)&quot;</span>) </span>
<span id="cb286-5"><a href="metropolis-hastings.html#cb286-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">lowess</span>(icecore[,<span class="dv">2</span>], icecore[,<span class="dv">3</span>]), <span class="at">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-189"></span>
<img src="bayesianS21_files/figure-html/unnamed-chunk-189-1.png" alt="Scatterplot of temperature versus carbon dioxide" width="672" />
<p class="caption">
Figure 18.2: Scatterplot of temperature versus carbon dioxide
</p>
</div>
<p>There seems to be a positive association. Linear regression seems reasonable for this problem.</p>
<p>Question is: The usual regression model assumes the error terms are independent. Is the assumption of independent error terms met for these data?</p>
<p>If <span class="math inline">\(\epsilon_t \stackrel{\text{iid}}{\sim}\)</span> Normal<span class="math inline">\((0, \sigma^2)\)</span> then our model has three parameters <span class="math inline">\(\beta_1, \beta_2, \sigma^2\)</span>.</p>
<p>These data are observed sequentially over time. We need to check for the possibility of temporal association in the error term</p>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb287-1"><a href="metropolis-hastings.html#cb287-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit ordinary linear regression of tmp on co2</span></span>
<span id="cb287-2"><a href="metropolis-hastings.html#cb287-2" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(tmp <span class="sc">~</span> co2, <span class="at">data=</span>icecore);  <span class="fu">summary</span>(fit)<span class="sc">$</span>coeff; <span class="fu">summary</span>(fit)<span class="sc">$</span>sigma</span></code></pre></div>
<pre><code>##              Estimate Std. Error t value  Pr(&gt;|t|)
## (Intercept) -23.02414   0.879543  -26.18 3.272e-66
## co2           0.07985   0.003834   20.83 8.767e-52</code></pre>
<pre><code>## [1] 1.533</code></pre>
<p><span class="math inline">\(\hat\beta_1 = -23\)</span>, <span class="math inline">\(\hat\beta_2 = 0.08\)</span>, <span class="math inline">\(\hat\sigma = 1.53\)</span></p>
<p>Normally distributed error terms is, strictly speaking, a fundamental assumption of the linear regression model but practically not the most important.</p>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="metropolis-hastings.html#cb290-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">resid</span>(fit), <span class="at">freq=</span>F, <span class="at">right=</span>F, <span class="at">breaks=</span><span class="dv">30</span>, </span>
<span id="cb290-2"><a href="metropolis-hastings.html#cb290-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;residual&quot;</span>, <span class="at">col=</span><span class="st">&quot;pink&quot;</span>)</span></code></pre></div>
<p><img src="bayesianS21_files/figure-html/unnamed-chunk-191-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Histogram of residuals looks like a bell curve or close enough. This is fine. What is a key assumption is that the error terms are independent. There isn’t a go to diagnostic for non-independence of error terms. Such a diagnostic only exists if there is some structure to the data such as spatial or temporal. In this case these data are observed over time so autocorrelation is meaningful!</p>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="metropolis-hastings.html#cb291-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb291-2"><a href="metropolis-hastings.html#cb291-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ts.plot</span>(<span class="fu">resid</span>(fit));<span class="fu">acf</span>(<span class="fu">resid</span>(fit))</span></code></pre></div>
<p><img src="bayesianS21_files/figure-html/unnamed-chunk-192-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>In addition to <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> being time series, it appears that the error term has time series component also. There is positive temporal association.</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="metropolis-hastings.html#cb292-1" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(<span class="fu">resid</span>(fit), <span class="at">plot=</span>F)[<span class="dv">1</span>]</span></code></pre></div>
<pre><code>## 
## Autocorrelations of series &#39;resid(fit)&#39;, by lag
## 
##     1 
## 0.517</code></pre>
<p>Lag-1 autocorrelation is 0.5. This is something we should not ignore. Sometimes you can have data that are observed sequentially over time but the relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> is such that the residuals are practically independent.</p>
<p>Here we have data observed over time but the relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> is such that the residuals are not independent (there is positive temporal association). So we gotta deal with this. This means our model can’t say <span class="math inline">\(\epsilon_t \stackrel{\text{iid}}\sim N(\boldsymbol{0}, \sigma^2).\)</span> Normality is okay, mean <span class="math inline">\(\boldsymbol{0}\)</span> is fine, constant variance is fine, the problem is the “iid” part (the error terms are not independent). There is no data transformation that’s gonna solve this problem. We need to accommodate it in the model itself.</p>
</div>
<div id="a-regression-model-with-correlated-errors" class="section level2" number="18.4">
<h2><span class="header-section-number">18.4</span> A regression model with correlated errors</h2>
<p>For the icecore data the ordinary regression model</p>
<p><span class="math display">\[
\boldsymbol{Y}=\left(\begin{array}{c}
Y_{1} \\
\vdots \\
Y_{n}
\end{array}\right) \sim \operatorname{Normal}_{n}\left(\mathbf{X} \boldsymbol{\beta}, \sigma^{2} \mathbf{I}\right)
\]</span></p>
<p>does not hold because the off diagonal of the covariance matrix is not all zeros like the standard model says. Let’s introduce one new parameter.</p>
<p>A covariance matrix (correlation matrix) has <span class="math inline">\((n-1) (n-2) / 2\)</span> covariances? We don’t want to fit a model with this many parameters. Is there a simple model that will account for the temporal association of the error terms but not require a bunch of parameters to estimate? Yes there is. Try assuming the error terms follow the AR(1) autoregressive process which says that each error term is correlated with the predecessor.</p>
<ul>
<li><span class="math inline">\(\text{cor}( \epsilon_i, \epsilon_{i+1} ) = \rho=\)</span> lag-1 autocorrelation</li>
<li><span class="math inline">\(\text{cor}( \epsilon_i , \epsilon_{i+2} ) = \rho^2=\)</span> lag-2 autocorrelation</li>
<li><span class="math inline">\(\text{cor}(\epsilon_i , \epsilon_{i+t} ) = \rho^t\)</span>, <span class="math inline">\(0 &lt; \rho &lt; 1\)</span></li>
</ul>
<p>
 
</p>
<p><span class="math display">\[
\boldsymbol{\Sigma}=\sigma^{2} \mathbf{C}_{\rho}=\sigma^{2}\left(\begin{array}{ccccc}
1 &amp; \rho &amp; \rho^{2} &amp; \cdots &amp; \rho^{n-1} \\
\rho &amp; 1 &amp; \rho &amp; \cdots &amp; \rho^{n-2} \\
\rho^{2} &amp; \rho &amp; 1 &amp; &amp; \rho^{n-3} \\
\vdots &amp; \vdots &amp; \vdots &amp; &amp; \vdots \\
\rho^{n-1} &amp; \rho^{n-2} &amp; \rho^{n-3} &amp; \cdots &amp; 1
\end{array}\right)
\]</span></p>
<p>The <span class="math inline">\(n \times n\)</span> covariance matrix looks like this. It has <span class="math inline">\(n^2\)</span> entries but only two parameters the variance <span class="math inline">\(\sigma^2\)</span> and the lag-1 autocorrelation <span class="math inline">\(\rho.\)</span></p>
<p>So the model parameters are more generally; <span class="math inline">\(\boldsymbol\beta = (\beta_1, \beta_2, …, \beta_p)\)</span> and <span class="math inline">\(\sigma^2\)</span> (the residual variance) and <span class="math inline">\(\rho\)</span> (the residual autocorrelation).</p>
<p>We have our data we have our model we just need to fit that model! We need to propose prior distributions for <span class="math inline">\(\boldsymbol \beta\)</span>, <span class="math inline">\(\sigma^2\)</span> and <span class="math inline">\(\rho\)</span>, do the Bayes rule calculation and determine the posterior distributions!</p>
<p>For <span class="math inline">\(\boldsymbol \beta\)</span> and <span class="math inline">\(\sigma^2\)</span> assume the normal and inverse-gamma priors. We get posteriors of those forms as well because those are conjugate priors. Note that when I say “posteriors of these forms,” I mean “full conditionals” of these forms. So let’s find the <strong>full conditionals</strong>.</p>
<p>
 
</p>
<p><span class="math inline">\(\{\boldsymbol{\beta} \mid \boldsymbol{y}, \mathbf{X}, \sigma^{2}, \rho\} \sim \operatorname{Normal}_{p}\left(\boldsymbol{\beta}_{n}, \boldsymbol{\Sigma}_{n}\right)\)</span></p>
<p>where</p>
<p><span class="math display">\[
\begin{array}{l}
\boldsymbol{\Sigma}_{n}=\left(\Sigma_{0}^{-1}+\mathbf{X}^{T} \mathbf{C}_{\rho}^{-1} \mathbf{X} / \sigma^{2}\right)^{-1} \\
\boldsymbol{\beta}_{n}=\boldsymbol{\Sigma}_{n}\left(\boldsymbol{\Sigma}_{0}^{-1} \boldsymbol{\beta}_{0}+\mathbf{X}^{T} \mathbf{C}_{\rho}^{-1} \boldsymbol{y} / \sigma^{2}\right)
\end{array}
\]</span>
and</p>
<p><span class="math inline">\(\{\sigma^{2} \mid \boldsymbol{y}, \mathbf{X}, \boldsymbol{\beta}, \rho\} \sim \operatorname{InvGamma}\left(\left[\nu_{0}+n\right] / 2,\left[\nu_{0} \sigma_{0}^{2}+\mathrm{SSR}_{\rho}\right] / 2\right)\)</span></p>
<p>where</p>
<p><span class="math display">\[
\operatorname{SSR}_{\rho}=(\boldsymbol{y}-\mathbf{X} \boldsymbol{\beta})^{T} \mathbf{C}_{\rho}^{-1}(\boldsymbol{y}-\mathbf{X} \boldsymbol{\beta}) .
\]</span></p>
<p><span class="math inline">\(\hat{\boldsymbol\beta}\)</span> is the usual “Generalized Least Squares” estimate of <span class="math inline">\(\boldsymbol{\beta}\)</span>. GLS includes this correlation matrix <span class="math inline">\(\mathbf C_\rho\)</span>.</p>
<p>What about <span class="math inline">\(\rho?\)</span> Turns out there is no conjugate prior for <span class="math inline">\(\rho\)</span> i.e., { <span class="math inline">\(\rho\)</span> | everything else } is not a nice form. So here’s what we’ll do. We’ll use the Gibbs sampler set-up. We’ll update <span class="math inline">\(\boldsymbol\beta\)</span> and <span class="math inline">\(\sigma^2\)</span> by Gibbs. But when we get to <span class="math inline">\(\rho\)</span> we’re gonna need to do a Metropolis update.</p>
<p>Let’s assume <span class="math inline">\(\rho \sim\)</span> Uniform<span class="math inline">\((0, 1)\)</span>. Given <span class="math inline">\(\{~\boldsymbol\beta^{(s)}, \sigma^{2(s)}, \rho^{(s)}~\}\)</span>, we will do our MCMC as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Update <span class="math inline">\(\boldsymbol{\beta}:\)</span> Sample
<span class="math display">\[
\boldsymbol{\beta}^{(s+1)} \sim \text { Normal}_{p}\left(\boldsymbol{\beta}_{n}, \boldsymbol{\Sigma}_{n}\right)
\]</span>
where <span class="math inline">\(\boldsymbol{\beta}_{n}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}_{n}\)</span> depend on <span class="math inline">\(\sigma^{2(s)}\)</span> and <span class="math inline">\(\rho^{(s)}\)</span>.</p></li>
<li><p>Update <span class="math inline">\(\sigma^{2}\)</span> : Sample
<span class="math display">\[
\sigma^{2(s+1)} \sim \operatorname{InvGamma}\left(\left[\nu_{0}+n\right] / 2,\left[\nu_{0} \sigma_{0}^{2}+\mathrm{SSR}_{\rho}\right] / 2\right)
\]</span>
where <span class="math inline">\(\operatorname{SSR}_{\rho}\)</span> depends on <span class="math inline">\(\boldsymbol{\beta}^{(s+1)}\)</span> and <span class="math inline">\(\rho^{(s)}\)</span></p></li>
<li><p>Update <span class="math inline">\(\rho\)</span> :</p></li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Propose <span class="math inline">\(\rho^{*} \sim\)</span> Uniform <span class="math inline">\(\left(\rho^{(s)}-\delta, \rho^{(s)}+\delta\right)\)</span>. If <span class="math inline">\(\rho^{*}&lt;0\)</span> then reassign it to be <span class="math inline">\(\left|\rho^{*}\right| ;\)</span> if <span class="math inline">\(\rho^{*}&gt;1\)</span>, reassign it to be <span class="math inline">\(2-\rho^{*}\)</span>.</li>
<li>Compute the acceptance ratio
<span class="math display">\[
r=\frac{p\left(\boldsymbol{y} \mid \mathbf{X}, \boldsymbol{\beta}^{(s+1)}, \sigma^{2(s+1)}, \rho^{*}\right) p\left(\rho^{*}\right)}{p\left(\boldsymbol{y} \mid \mathbf{X}, \boldsymbol{\beta}^{(s+1)}, \sigma^{2(s+1)}, \rho^{(s)}\right) p\left(\rho^{(s)}\right)}
\]</span></li>
<li>Sample <span class="math inline">\(u \sim\)</span> uniform <span class="math inline">\((0,1)\)</span>. If <span class="math inline">\(u&lt;r\)</span> set <span class="math inline">\(\rho^{(s+1)}=\rho^{*}\)</span>, otherwise set <span class="math inline">\(\rho^{(s+1)}=\rho^{(s)}\)</span>.</li>
</ol>
<p>
 
</p>
<p>It’s not obvious that this proposal distribution described in step 3a is symmetric as required by the metropolis algorithm. Turns out it is. This is called reflecting random walk. Instead of going negative, bounce back by that amount. Instead of going above 1 bounce back by that amount</p>
<p>Let’s run this Gibbs sampler!</p>
</div>
<div id="analysis-of-the-ice-core-data" class="section level2" number="18.5">
<h2><span class="header-section-number">18.5</span> Analysis of the ice core data</h2>
<p>Priors:</p>
<ul>
<li><p><span class="math inline">\(\boldsymbol\beta_0 = \boldsymbol0\)</span>,</p></li>
<li><p><span class="math inline">\(\Sigma_0 = 1000\times \mathbf{I}_2,\)</span> diagonal with big numbers on the diagonal. In other words, a diffuse prior</p></li>
<li><p><span class="math inline">\(\nu_0 = 1\)</span> “prior sample size” of 1 versus data sample size of 200 (because diffuse prior)</p></li>
</ul>
<p>starting values:</p>
<ul>
<li>start <span class="math inline">\(\boldsymbol\beta\)</span> at the OLS estimate of <span class="math inline">\(\boldsymbol\beta\)</span></li>
<li>start <span class="math inline">\(\sigma^2\)</span> at the OLS estimate of <span class="math inline">\(\sigma^2\)</span></li>
<li>start <span class="math inline">\(\rho\)</span> at the sample lag-1 autocorrelation of the residuals from the OLS fit</li>
</ul>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb294-1"><a href="metropolis-hastings.html#cb294-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Gibbs sampler for &#39;Bayesian GLS&#39; model fit</span></span>
<span id="cb294-2"><a href="metropolis-hastings.html#cb294-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">dim</span>(icecore)[<span class="dv">1</span>];  </span>
<span id="cb294-3"><a href="metropolis-hastings.html#cb294-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> icecore[,<span class="dv">3</span>];</span>
<span id="cb294-4"><a href="metropolis-hastings.html#cb294-4" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">1</span>,n), icecore[,<span class="dv">2</span>]);  </span>
<span id="cb294-5"><a href="metropolis-hastings.html#cb294-5" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">2</span>;</span>
<span id="cb294-6"><a href="metropolis-hastings.html#cb294-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb294-7"><a href="metropolis-hastings.html#cb294-7" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(X) <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>n</span>
<span id="cb294-8"><a href="metropolis-hastings.html#cb294-8" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(X) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;x1&quot;</span>,<span class="st">&quot;x2&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="metropolis-hastings.html#cb295-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Preliminary calculations </span></span>
<span id="cb295-2"><a href="metropolis-hastings.html#cb295-2" aria-hidden="true" tabindex="-1"></a>lmfit  <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> X)</span>
<span id="cb295-3"><a href="metropolis-hastings.html#cb295-3" aria-hidden="true" tabindex="-1"></a>beta   <span class="ot">&lt;-</span> lmfit<span class="sc">$</span>coef</span>
<span id="cb295-4"><a href="metropolis-hastings.html#cb295-4" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="ot">&lt;-</span> <span class="fu">summary</span>(lmfit)<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb295-5"><a href="metropolis-hastings.html#cb295-5" aria-hidden="true" tabindex="-1"></a>rho    <span class="ot">&lt;-</span> <span class="fu">acf</span>(<span class="fu">resid</span>(lmfit), <span class="at">plot=</span>F)<span class="sc">$</span>acf[<span class="dv">2</span>] <span class="co">#tuning parameter</span></span>
<span id="cb295-6"><a href="metropolis-hastings.html#cb295-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb295-7"><a href="metropolis-hastings.html#cb295-7" aria-hidden="true" tabindex="-1"></a><span class="co"># and prior parameters</span></span>
<span id="cb295-8"><a href="metropolis-hastings.html#cb295-8" aria-hidden="true" tabindex="-1"></a>nu<span class="fl">.0</span>       <span class="ot">&lt;-</span> <span class="dv">1</span>;  </span>
<span id="cb295-9"><a href="metropolis-hastings.html#cb295-9" aria-hidden="true" tabindex="-1"></a>sigma2<span class="fl">.0</span>   <span class="ot">&lt;-</span> <span class="dv">1</span>;  </span>
<span id="cb295-10"><a href="metropolis-hastings.html#cb295-10" aria-hidden="true" tabindex="-1"></a>Sigma0.inv <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="dv">2</span>) <span class="sc">/</span> <span class="dv">1000</span></span>
<span id="cb295-11"><a href="metropolis-hastings.html#cb295-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb295-12"><a href="metropolis-hastings.html#cb295-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Now run the MCMC!</span></span>
<span id="cb295-13"><a href="metropolis-hastings.html#cb295-13" aria-hidden="true" tabindex="-1"></a>D     <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="fu">outer</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="dv">1</span><span class="sc">:</span>n, <span class="st">&quot;-&quot;</span>))</span>
<span id="cb295-14"><a href="metropolis-hastings.html#cb295-14" aria-hidden="true" tabindex="-1"></a>S     <span class="ot">&lt;-</span> <span class="dv">1000</span> </span>
<span id="cb295-15"><a href="metropolis-hastings.html#cb295-15" aria-hidden="true" tabindex="-1"></a>ac    <span class="ot">&lt;-</span> <span class="dv">0</span>; </span>
<span id="cb295-16"><a href="metropolis-hastings.html#cb295-16" aria-hidden="true" tabindex="-1"></a>delta <span class="ot">&lt;-</span> <span class="fl">0.1</span></span>
<span id="cb295-17"><a href="metropolis-hastings.html#cb295-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb295-18"><a href="metropolis-hastings.html#cb295-18" aria-hidden="true" tabindex="-1"></a>beta.chain   <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, S, p)</span>
<span id="cb295-19"><a href="metropolis-hastings.html#cb295-19" aria-hidden="true" tabindex="-1"></a>sigma2.chain <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, S)</span>
<span id="cb295-20"><a href="metropolis-hastings.html#cb295-20" aria-hidden="true" tabindex="-1"></a>rho.chain    <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, S);</span></code></pre></div>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="metropolis-hastings.html#cb296-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mvtnorm) </span>
<span id="cb296-2"><a href="metropolis-hastings.html#cb296-2" aria-hidden="true" tabindex="-1"></a>run.time     <span class="ot">&lt;-</span> <span class="fu">proc.time</span>()</span>
<span id="cb296-3"><a href="metropolis-hastings.html#cb296-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb296-4"><a href="metropolis-hastings.html#cb296-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>S)</span>
<span id="cb296-5"><a href="metropolis-hastings.html#cb296-5" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb296-6"><a href="metropolis-hastings.html#cb296-6" aria-hidden="true" tabindex="-1"></a> <span class="co"># Update beta first </span></span>
<span id="cb296-7"><a href="metropolis-hastings.html#cb296-7" aria-hidden="true" tabindex="-1"></a> C.rho.inv <span class="ot">&lt;-</span> <span class="fu">solve</span>( rho<span class="sc">^</span>D )</span>
<span id="cb296-8"><a href="metropolis-hastings.html#cb296-8" aria-hidden="true" tabindex="-1"></a> V.beta    <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> C.rho.inv <span class="sc">%*%</span> X <span class="sc">/</span> sigma2 <span class="sc">+</span> Sigma0.inv)</span>
<span id="cb296-9"><a href="metropolis-hastings.html#cb296-9" aria-hidden="true" tabindex="-1"></a> m.beta    <span class="ot">&lt;-</span> V.beta <span class="sc">%*%</span> (<span class="fu">t</span>(X) <span class="sc">%*%</span> C.rho.inv <span class="sc">%*%</span> y <span class="sc">/</span> sigma2) </span>
<span id="cb296-10"><a href="metropolis-hastings.html#cb296-10" aria-hidden="true" tabindex="-1"></a> beta      <span class="ot">&lt;-</span> <span class="fu">rmvnorm</span>(<span class="dv">1</span>, <span class="at">mean=</span>m.beta, <span class="at">sigma=</span>V.beta)[<span class="dv">1</span>,]</span>
<span id="cb296-11"><a href="metropolis-hastings.html#cb296-11" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb296-12"><a href="metropolis-hastings.html#cb296-12" aria-hidden="true" tabindex="-1"></a> <span class="co"># Now update sigma2</span></span>
<span id="cb296-13"><a href="metropolis-hastings.html#cb296-13" aria-hidden="true" tabindex="-1"></a> SSR    <span class="ot">&lt;-</span> <span class="fu">t</span>(y <span class="sc">-</span> X <span class="sc">%*%</span> beta) <span class="sc">%*%</span> C.rho.inv <span class="sc">%*%</span> (y <span class="sc">-</span> X <span class="sc">%*%</span> beta)</span>
<span id="cb296-14"><a href="metropolis-hastings.html#cb296-14" aria-hidden="true" tabindex="-1"></a> sigma2 <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span><span class="fu">rgamma</span>(<span class="dv">1</span>, (nu<span class="fl">.0</span><span class="sc">+</span>n)<span class="sc">/</span><span class="dv">2</span>, (nu<span class="fl">.0</span><span class="sc">*</span>sigma2<span class="fl">.0</span> <span class="sc">+</span> SSR)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb296-15"><a href="metropolis-hastings.html#cb296-15" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb296-16"><a href="metropolis-hastings.html#cb296-16" aria-hidden="true" tabindex="-1"></a> <span class="co"># Now Metropolis update of rho</span></span>
<span id="cb296-17"><a href="metropolis-hastings.html#cb296-17" aria-hidden="true" tabindex="-1"></a> rho.star <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="fu">runif</span>(<span class="dv">1</span>, rho<span class="sc">-</span>delta, rho<span class="sc">+</span>delta))</span>
<span id="cb296-18"><a href="metropolis-hastings.html#cb296-18" aria-hidden="true" tabindex="-1"></a> rho.star <span class="ot">&lt;-</span> <span class="fu">min</span>(rho.star, <span class="dv">2</span><span class="sc">-</span>rho.star)</span>
<span id="cb296-19"><a href="metropolis-hastings.html#cb296-19" aria-hidden="true" tabindex="-1"></a> log.r    <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">0.5</span> <span class="sc">*</span> ( <span class="fu">determinant</span>( rho.star<span class="sc">^</span>D, <span class="at">log=</span>T)<span class="sc">$</span>mod <span class="sc">-</span> </span>
<span id="cb296-20"><a href="metropolis-hastings.html#cb296-20" aria-hidden="true" tabindex="-1"></a>                   <span class="fu">determinant</span>( rho<span class="sc">^</span>D, <span class="at">log=</span>T)<span class="sc">$</span>mod <span class="sc">+</span> </span>
<span id="cb296-21"><a href="metropolis-hastings.html#cb296-21" aria-hidden="true" tabindex="-1"></a>   <span class="fu">sum</span>( <span class="fu">diag</span>( (y <span class="sc">-</span> X <span class="sc">%*%</span> beta) <span class="sc">%*%</span> <span class="fu">t</span>(y <span class="sc">-</span> X <span class="sc">%*%</span> beta) <span class="sc">%*%</span> </span>
<span id="cb296-22"><a href="metropolis-hastings.html#cb296-22" aria-hidden="true" tabindex="-1"></a>    ( <span class="fu">solve</span>(rho.star<span class="sc">^</span>D) <span class="sc">-</span> <span class="fu">solve</span>(rho<span class="sc">^</span>D) ) ) ) <span class="sc">/</span> sigma2 )</span>
<span id="cb296-23"><a href="metropolis-hastings.html#cb296-23" aria-hidden="true" tabindex="-1"></a> <span class="cf">if</span>(<span class="fu">log</span>(<span class="fu">runif</span>(<span class="dv">1</span>)) <span class="sc">&lt;</span> log.r) { rho <span class="ot">&lt;-</span> rho.star;  ac <span class="ot">&lt;-</span> ac <span class="sc">+</span> <span class="dv">1</span>; }</span>
<span id="cb296-24"><a href="metropolis-hastings.html#cb296-24" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb296-25"><a href="metropolis-hastings.html#cb296-25" aria-hidden="true" tabindex="-1"></a> <span class="co"># Save the updates!</span></span>
<span id="cb296-26"><a href="metropolis-hastings.html#cb296-26" aria-hidden="true" tabindex="-1"></a> beta.chain[s,]  <span class="ot">&lt;-</span> beta;  </span>
<span id="cb296-27"><a href="metropolis-hastings.html#cb296-27" aria-hidden="true" tabindex="-1"></a> sigma2.chain[s] <span class="ot">&lt;-</span> sigma2; </span>
<span id="cb296-28"><a href="metropolis-hastings.html#cb296-28" aria-hidden="true" tabindex="-1"></a> rho.chain[s]    <span class="ot">&lt;-</span> rho;</span>
<span id="cb296-29"><a href="metropolis-hastings.html#cb296-29" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb296-30"><a href="metropolis-hastings.html#cb296-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb296-31"><a href="metropolis-hastings.html#cb296-31" aria-hidden="true" tabindex="-1"></a>run.time <span class="ot">&lt;-</span> <span class="fu">proc.time</span>() <span class="sc">-</span> run.time</span></code></pre></div>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="metropolis-hastings.html#cb297-1" aria-hidden="true" tabindex="-1"></a>ac <span class="sc">/</span> S  <span class="co"># acceptance rate</span></span></code></pre></div>
<pre><code>## [1] 0.258</code></pre>
<p>Tuning parameter is <span class="math inline">\(\delta\)</span>. Remember our rule of thumb for tuning parameters and acceptance rates. A common strategy for tuning parameter is; Come up with a value for <span class="math inline">\(\delta\)</span> some way some how. If the acceptance rate &lt; 0.20 make <span class="math inline">\(\delta\)</span> smaller if accept rate <span class="math inline">\(&gt; 0.50\)</span> make <span class="math inline">\(\delta\)</span> bigger (<span class="math inline">\(\delta\)</span> indicates the likely size of the proposed jump)</p>
<p>Our accept rate was 0.26 so that should be fine!</p>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="metropolis-hastings.html#cb299-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb299-2"><a href="metropolis-hastings.html#cb299-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb299-3"><a href="metropolis-hastings.html#cb299-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(rho.chain, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;scan&quot;</span>, <span class="at">ylab=</span><span class="fu">expression</span>(rho))</span>
<span id="cb299-4"><a href="metropolis-hastings.html#cb299-4" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(rho.chain)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-198"></span>
<img src="bayesianS21_files/figure-html/unnamed-chunk-198-1.png" alt="Trace plot and autocorrelation function for the rho chain" width="672" />
<p class="caption">
Figure 18.3: Trace plot and autocorrelation function for the rho chain
</p>
</div>
<p>This is not good. 30 updates of this Markov chain are NOT 30 samples from the posterior. There’s just too much correlation.</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="metropolis-hastings.html#cb300-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mcmcse)</span>
<span id="cb300-2"><a href="metropolis-hastings.html#cb300-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ess</span>(rho.chain)</span></code></pre></div>
<pre><code>## [1] 8.319</code></pre>
<p>In fact for 1000 iterations of the “Metropolised” Gibbs sampler the effective sample size was 8. Meaning our 1000 iterations was the statistical equivalence of 8 independent observations.</p>
<p>So here’s what we do. Don’t run 1000 iterations. Run 25,000 iterations. However, storing 25,000 sets of parameter values when consecutive values are practically the same (which they are here given this high autocorrelation) is not efficient. So what people do for chains with really high autocorrelation is to get a set of <span class="math inline">\(S\)</span> samples, run the chain for <span class="math inline">\(S \times T\)</span> iterations but only save every <span class="math inline">\(T^{\text{th}}\)</span> update.</p>
<p>Let’s do <span class="math inline">\(S = 1000,~ T = 25\)</span></p>
<p>So we’ll run 25,000 updates(scans) of the Gibbs sampler but only save every 25th result. So we’ll get 1000 values. This is called <strong>“thinning”</strong> we thin our output from 25,000 values to just 1000. The lag-1 autocorrelation in the thinned chain will be the lag-25 autocorrelation in the unthinned chain. The lag 2 autocorrelation in the thinned chain chain will be the lag-50 autocorrelation from the unthinned chain.</p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="metropolis-hastings.html#cb302-1" aria-hidden="true" tabindex="-1"></a>run.time  <span class="co"># run time in seconds</span></span></code></pre></div>
<pre><code>##    user  system elapsed 
##  36.979   1.803  38.800</code></pre>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="metropolis-hastings.html#cb304-1" aria-hidden="true" tabindex="-1"></a><span class="co"># projected run time in minutes</span></span>
<span id="cb304-2"><a href="metropolis-hastings.html#cb304-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This should take about 25 times the previous&#39;</span></span>
<span id="cb304-3"><a href="metropolis-hastings.html#cb304-3" aria-hidden="true" tabindex="-1"></a><span class="dv">25</span> <span class="sc">*</span> run.time <span class="sc">/</span> <span class="dv">60</span>   </span></code></pre></div>
<pre><code>##    user  system elapsed 
## 15.4079  0.7512 16.1667</code></pre>
<p>Set it off, then go get a cup of coffee.</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="metropolis-hastings.html#cb306-1" aria-hidden="true" tabindex="-1"></a>S <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb306-2"><a href="metropolis-hastings.html#cb306-2" aria-hidden="true" tabindex="-1"></a>T <span class="ot">&lt;-</span> <span class="dv">25</span></span>
<span id="cb306-3"><a href="metropolis-hastings.html#cb306-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb306-4"><a href="metropolis-hastings.html#cb306-4" aria-hidden="true" tabindex="-1"></a>beta.chain   <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, S, p);  ac <span class="ot">&lt;-</span> <span class="dv">0</span>;</span>
<span id="cb306-5"><a href="metropolis-hastings.html#cb306-5" aria-hidden="true" tabindex="-1"></a>sigma2.chain <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, S);  rho.chain <span class="ot">&lt;-</span><span class="fu">rep</span>(<span class="cn">NA</span>, S);</span>
<span id="cb306-6"><a href="metropolis-hastings.html#cb306-6" aria-hidden="true" tabindex="-1"></a>run.time     <span class="ot">&lt;-</span> <span class="fu">proc.time</span>()</span>
<span id="cb306-7"><a href="metropolis-hastings.html#cb306-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb306-8"><a href="metropolis-hastings.html#cb306-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>S)</span>
<span id="cb306-9"><a href="metropolis-hastings.html#cb306-9" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb306-10"><a href="metropolis-hastings.html#cb306-10" aria-hidden="true" tabindex="-1"></a> <span class="cf">for</span>(t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>T){ </span>
<span id="cb306-11"><a href="metropolis-hastings.html#cb306-11" aria-hidden="true" tabindex="-1"></a>  <span class="do">###</span></span>
<span id="cb306-12"><a href="metropolis-hastings.html#cb306-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Update beta first </span></span>
<span id="cb306-13"><a href="metropolis-hastings.html#cb306-13" aria-hidden="true" tabindex="-1"></a>  <span class="do">###</span></span>
<span id="cb306-14"><a href="metropolis-hastings.html#cb306-14" aria-hidden="true" tabindex="-1"></a>  C.rho.inv <span class="ot">&lt;-</span> <span class="fu">solve</span>( rho<span class="sc">^</span>D )</span>
<span id="cb306-15"><a href="metropolis-hastings.html#cb306-15" aria-hidden="true" tabindex="-1"></a>  V.beta    <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> C.rho.inv <span class="sc">%*%</span> X <span class="sc">/</span> sigma2 <span class="sc">+</span> Sigma0.inv)</span>
<span id="cb306-16"><a href="metropolis-hastings.html#cb306-16" aria-hidden="true" tabindex="-1"></a>  m.beta    <span class="ot">&lt;-</span> V.beta <span class="sc">%*%</span> (<span class="fu">t</span>(X) <span class="sc">%*%</span> C.rho.inv <span class="sc">%*%</span> y <span class="sc">/</span> sigma2) </span>
<span id="cb306-17"><a href="metropolis-hastings.html#cb306-17" aria-hidden="true" tabindex="-1"></a>  beta      <span class="ot">&lt;-</span> <span class="fu">rmvnorm</span>(<span class="dv">1</span>, <span class="at">mean=</span>m.beta, <span class="at">sigma=</span>V.beta)[<span class="dv">1</span>,]</span>
<span id="cb306-18"><a href="metropolis-hastings.html#cb306-18" aria-hidden="true" tabindex="-1"></a>  <span class="do">###</span></span>
<span id="cb306-19"><a href="metropolis-hastings.html#cb306-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Now update sigma2</span></span>
<span id="cb306-20"><a href="metropolis-hastings.html#cb306-20" aria-hidden="true" tabindex="-1"></a>  <span class="do">###</span></span>
<span id="cb306-21"><a href="metropolis-hastings.html#cb306-21" aria-hidden="true" tabindex="-1"></a>  SSR    <span class="ot">&lt;-</span> <span class="fu">t</span>(y <span class="sc">-</span> X <span class="sc">%*%</span> beta) <span class="sc">%*%</span> C.rho.inv <span class="sc">%*%</span> (y <span class="sc">-</span> X <span class="sc">%*%</span> beta)</span>
<span id="cb306-22"><a href="metropolis-hastings.html#cb306-22" aria-hidden="true" tabindex="-1"></a>  sigma2 <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span><span class="fu">rgamma</span>(<span class="dv">1</span>, (nu<span class="fl">.0</span><span class="sc">+</span>n)<span class="sc">/</span><span class="dv">2</span>, (nu<span class="fl">.0</span><span class="sc">*</span>sigma2<span class="fl">.0</span> <span class="sc">+</span> SSR)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb306-23"><a href="metropolis-hastings.html#cb306-23" aria-hidden="true" tabindex="-1"></a>  <span class="do">### </span></span>
<span id="cb306-24"><a href="metropolis-hastings.html#cb306-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Now Metropolis update of rho</span></span>
<span id="cb306-25"><a href="metropolis-hastings.html#cb306-25" aria-hidden="true" tabindex="-1"></a>  <span class="do">###</span></span>
<span id="cb306-26"><a href="metropolis-hastings.html#cb306-26" aria-hidden="true" tabindex="-1"></a>  rho.star <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="fu">runif</span>(<span class="dv">1</span>, rho<span class="sc">-</span>delta, rho<span class="sc">+</span>delta))</span>
<span id="cb306-27"><a href="metropolis-hastings.html#cb306-27" aria-hidden="true" tabindex="-1"></a>  rho.star <span class="ot">&lt;-</span> <span class="fu">min</span>(rho.star, <span class="dv">2</span><span class="sc">-</span>rho.star)</span>
<span id="cb306-28"><a href="metropolis-hastings.html#cb306-28" aria-hidden="true" tabindex="-1"></a>  log.r    <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">0.5</span> <span class="sc">*</span> ( <span class="fu">determinant</span>( rho.star<span class="sc">^</span>D, <span class="at">log=</span>T)<span class="sc">$</span>mod <span class="sc">-</span> </span>
<span id="cb306-29"><a href="metropolis-hastings.html#cb306-29" aria-hidden="true" tabindex="-1"></a>                    <span class="fu">determinant</span>( rho<span class="sc">^</span>D, <span class="at">log=</span>T)<span class="sc">$</span>mod <span class="sc">+</span> </span>
<span id="cb306-30"><a href="metropolis-hastings.html#cb306-30" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sum</span>( <span class="fu">diag</span>( (y <span class="sc">-</span> X <span class="sc">%*%</span> beta) <span class="sc">%*%</span> <span class="fu">t</span>(y <span class="sc">-</span> X <span class="sc">%*%</span> beta) <span class="sc">%*%</span> </span>
<span id="cb306-31"><a href="metropolis-hastings.html#cb306-31" aria-hidden="true" tabindex="-1"></a>      ( <span class="fu">solve</span>(rho.star<span class="sc">^</span>D) <span class="sc">-</span> <span class="fu">solve</span>(rho<span class="sc">^</span>D) ) ) ) <span class="sc">/</span> sigma2 )</span>
<span id="cb306-32"><a href="metropolis-hastings.html#cb306-32" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="fu">log</span>(<span class="fu">runif</span>(<span class="dv">1</span>)) <span class="sc">&lt;</span> log.r) { rho <span class="ot">&lt;-</span> rho.star;  ac <span class="ot">&lt;-</span> ac <span class="sc">+</span> <span class="dv">1</span>; }</span>
<span id="cb306-33"><a href="metropolis-hastings.html#cb306-33" aria-hidden="true" tabindex="-1"></a> <span class="do">###</span></span>
<span id="cb306-34"><a href="metropolis-hastings.html#cb306-34" aria-hidden="true" tabindex="-1"></a> } <span class="co"># Save the current value, but only after T scans</span></span>
<span id="cb306-35"><a href="metropolis-hastings.html#cb306-35" aria-hidden="true" tabindex="-1"></a> <span class="do">###</span></span>
<span id="cb306-36"><a href="metropolis-hastings.html#cb306-36" aria-hidden="true" tabindex="-1"></a> beta.chain[s,]  <span class="ot">&lt;-</span> beta;  </span>
<span id="cb306-37"><a href="metropolis-hastings.html#cb306-37" aria-hidden="true" tabindex="-1"></a> sigma2.chain[s] <span class="ot">&lt;-</span> sigma2; </span>
<span id="cb306-38"><a href="metropolis-hastings.html#cb306-38" aria-hidden="true" tabindex="-1"></a> rho.chain[s]    <span class="ot">&lt;-</span> rho;</span>
<span id="cb306-39"><a href="metropolis-hastings.html#cb306-39" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb306-40"><a href="metropolis-hastings.html#cb306-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb306-41"><a href="metropolis-hastings.html#cb306-41" aria-hidden="true" tabindex="-1"></a>(run.time <span class="ot">&lt;-</span> <span class="fu">proc.time</span>() <span class="sc">-</span> run.time)</span></code></pre></div>
<pre><code>##    user  system elapsed 
##  923.45   45.02  969.38</code></pre>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="metropolis-hastings.html#cb308-1" aria-hidden="true" tabindex="-1"></a>ac <span class="sc">/</span> (S<span class="sc">*</span>T)  <span class="co"># acceptance rate </span></span></code></pre></div>
<pre><code>## [1] 0.2762</code></pre>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="metropolis-hastings.html#cb310-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s look at trace plot and autocorrelation function for the rho chain</span></span>
<span id="cb310-2"><a href="metropolis-hastings.html#cb310-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb310-3"><a href="metropolis-hastings.html#cb310-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb310-4"><a href="metropolis-hastings.html#cb310-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(rho.chain, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;scan/T&quot;</span>, <span class="at">ylab=</span><span class="fu">expression</span>(rho))</span>
<span id="cb310-5"><a href="metropolis-hastings.html#cb310-5" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(rho.chain)</span></code></pre></div>
<p><img src="bayesianS21_files/figure-html/unnamed-chunk-203-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Okay, that’s better</p>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="metropolis-hastings.html#cb311-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ess</span>(rho.chain)</span></code></pre></div>
<pre><code>## [1] 250.3</code></pre>
<p>So the thinning was effective. It’s not that the thinned chain contains more information than the unthinned chain. But it’s practically as good and saves storage.</p>
<p>We should have a good approximation to the posterior. Let’s start summarizing it. Let’s consider posterior inference about <span class="math inline">\(\beta_2.\)</span></p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="metropolis-hastings.html#cb313-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">density</span>(beta.chain[,<span class="dv">2</span>], <span class="at">adj=</span><span class="dv">2</span>), <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">xlab=</span><span class="fu">expression</span>(beta[<span class="dv">2</span>]), </span>
<span id="cb313-2"><a href="metropolis-hastings.html#cb313-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab=</span><span class="fu">expression</span>(<span class="fu">p</span>(beta[<span class="dv">2</span>]<span class="sc">*</span><span class="st">&quot;|&quot;</span><span class="sc">*</span>y)), <span class="at">main=</span><span class="st">&quot;&quot;</span>) </span>
<span id="cb313-3"><a href="metropolis-hastings.html#cb313-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">quantile</span>(beta.chain[,<span class="dv">2</span>], <span class="at">prob=</span><span class="fu">c</span>(.<span class="dv">025</span>, .<span class="dv">975</span>)), <span class="at">lty=</span><span class="dv">2</span>) </span></code></pre></div>
<p><img src="bayesianS21_files/figure-html/unnamed-chunk-205-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Posterior density estimate Mostly above 0</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="metropolis-hastings.html#cb314-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">quantile</span>(beta.chain[,<span class="dv">2</span>], <span class="at">prob=</span><span class="fu">c</span>(.<span class="dv">025</span>,.<span class="dv">25</span>,.<span class="dv">5</span>,.<span class="dv">75</span>,.<span class="dv">975</span>)),<span class="dv">3</span>)</span></code></pre></div>
<pre><code>##  2.5%   25%   50%   75% 97.5% 
## 0.010 0.021 0.028 0.034 0.048</code></pre>
<p>95% posterior interval is [.01,.05] which is &gt; 0, so the data give pretty compelling evidence that there exists a positive association between temperature and CO<span class="math inline">\(_2\)</span> over the millenia.</p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="metropolis-hastings.html#cb316-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">c</span>(<span class="fu">mean</span>(beta.chain[,<span class="dv">1</span>]),<span class="fu">mean</span>(beta.chain[,<span class="dv">2</span>])),<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] -11.032   0.028</code></pre>
<p>Note:</p>
<p>When we fit the model by OLS we got <span class="math inline">\(\hat\beta_2 = 0.08\)</span>. Using this “Bayesian GLS” model we get <span class="math inline">\(\hat \beta_2 = 0.03\)</span><br />
</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="metropolis-hastings.html#cb318-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fitting AR(1) to regression</span></span>
<span id="cb318-2"><a href="metropolis-hastings.html#cb318-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(orcutt)</span>
<span id="cb318-3"><a href="metropolis-hastings.html#cb318-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">summary</span>(<span class="fu">cochrane.orcutt</span>(fit))<span class="sc">$</span>coef,<span class="dv">3</span>)</span></code></pre></div>
<pre><code>##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  -10.814      1.669  -6.479        0
## co2            0.026      0.007   3.701        0</code></pre>
<p>Coefficients similar to Bayesian result</p>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="metropolis-hastings.html#cb320-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(y <span class="sc">~</span> X[,<span class="dv">2</span>], <span class="at">xlab=</span><span class="fu">expression</span>(CO[<span class="dv">2</span>]), <span class="at">ylab=</span><span class="st">&quot;temperature&quot;</span>) </span>
<span id="cb320-2"><a href="metropolis-hastings.html#cb320-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">apply</span>(beta.chain, <span class="dv">2</span>, mean), <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb320-3"><a href="metropolis-hastings.html#cb320-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(lmfit<span class="sc">$</span>coef, <span class="at">col=</span><span class="st">&quot;pink&quot;</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb320-4"><a href="metropolis-hastings.html#cb320-4" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">inset=</span>.<span class="dv">05</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;pink&quot;</span>,<span class="st">&quot;black&quot;</span>), </span>
<span id="cb320-5"><a href="metropolis-hastings.html#cb320-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;OLS estimate&quot;</span>, <span class="st">&quot;Bayesian GLS&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-209"></span>
<img src="bayesianS21_files/figure-html/unnamed-chunk-209-1.png" alt="Compare 'Bayesian GLS' estimate of regression line with the OLS estimate." width="672" />
<p class="caption">
Figure 18.4: Compare ‘Bayesian GLS’ estimate of regression line with the OLS estimate.
</p>
</div>
<p>This shows the raw data, the OLS line in pink and the GLS line in black. The GLS line has positive slope but A LOT less steep than the OLS line.</p>
<p>Even though the pink line is the one that best fits these points by least squares criterion, given the correlation structure of the data the black line provides the more reliable estimate of the true association.</p>
<p>Any Ideas as to why? Hoff provides the explanation that for OLS estimation, the small number of data points with high <span class="math inline">\(y\)</span>-values have a larger amount of influence on the estimate of <span class="math inline">\(\boldsymbol\beta\)</span>. In contrast, the GLS model recognizes that many of these extreme points are highly correlated with one another and down-weights their influence.</p>
<p>Student Question: If we directly used the 25000 unthinned values would we have gotten similar posterior conclusions?¿</p>
<p>Ans: Yes I believe so because <span class="math inline">\(\theta^{(1)}, \theta^{(2)},...,\theta^{(26)},\)</span> <span class="math inline">\(\theta^{(2)}\)</span> through <span class="math inline">\(\theta^{(25)}\)</span> don’t contribute a whole lot. They’re just a whole bunch more values that are probably between <span class="math inline">\(\theta^{(1)}\)</span> and <span class="math inline">\(\theta^{(26)}\)</span></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="generalized-linear-models-the-metropolis-algorithm.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bayesianS21.pdf", "bayesianS21.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
