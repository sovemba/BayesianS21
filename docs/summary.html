<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lecture 21 Summary | Bayesian Statistics lecture notes</title>
  <meta name="description" content="Lecture 21 Summary | Bayesian Statistics lecture notes" />
  <meta name="generator" content="bookdown 0.22.2 and GitBook 2.6.7" />

  <meta property="og:title" content="Lecture 21 Summary | Bayesian Statistics lecture notes" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lecture 21 Summary | Bayesian Statistics lecture notes" />
  
  
  

<meta name="author" content="Chisom Onyishi" />


<meta name="date" content="2021-06-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="stan-poisson-regression.html"/>

<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian statistics notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Belief and Probability</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#example"><i class="fa fa-check"></i><b>1.1</b> Example:</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#random-variables"><i class="fa fa-check"></i><b>1.2</b> Random Variables</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#binomial"><i class="fa fa-check"></i><b>1.3</b> Binomial distribution</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#poisson"><i class="fa fa-check"></i><b>1.4</b> Poisson distribution</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#continuous-random-variables"><i class="fa fa-check"></i><b>1.5</b> Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="index.html"><a href="index.html#example-normalmu-10.75-sigma0.8"><i class="fa fa-check"></i><b>1.5.1</b> Example: Normal(<span class="math inline">\(\mu = 10.75, \sigma=0.8\)</span>)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="exchangeability.html"><a href="exchangeability.html"><i class="fa fa-check"></i><b>2</b> Exchangeability</a>
<ul>
<li class="chapter" data-level="2.1" data-path="exchangeability.html"><a href="exchangeability.html#discrete-joint-distributions"><i class="fa fa-check"></i><b>2.1</b> Discrete joint distributions</a></li>
<li class="chapter" data-level="2.2" data-path="exchangeability.html"><a href="exchangeability.html#bayesrule"><i class="fa fa-check"></i><b>2.2</b> Bayes’ rule and parameter estimation</a></li>
<li class="chapter" data-level="2.3" data-path="exchangeability.html"><a href="exchangeability.html#independent-random-variables"><i class="fa fa-check"></i><b>2.3</b> Independent random variables</a></li>
<li class="chapter" data-level="2.4" data-path="exchangeability.html"><a href="exchangeability.html#exchangeability-1"><i class="fa fa-check"></i><b>2.4</b> Exchangeability</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="binomial-1.html"><a href="binomial-1.html"><i class="fa fa-check"></i><b>3</b> Binomial</a>
<ul>
<li class="chapter" data-level="3.1" data-path="binomial-1.html"><a href="binomial-1.html#example---exchangeable-binary-data"><i class="fa fa-check"></i><b>3.1</b> Example - Exchangeable binary data</a></li>
<li class="chapter" data-level="3.2" data-path="binomial-1.html"><a href="binomial-1.html#the-beta-distribution"><i class="fa fa-check"></i><b>3.2</b> The beta distribution</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="binomial-1.html"><a href="binomial-1.html#properties-of-the-beta-distribution"><i class="fa fa-check"></i><b>3.2.1</b> Properties of the beta distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="binomial-1.html"><a href="binomial-1.html#binomial-distribution"><i class="fa fa-check"></i><b>3.3</b> Binomial distribution</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="binomial-1.html"><a href="binomial-1.html#posterior-inference-for-a-binomial-sampling-model"><i class="fa fa-check"></i><b>3.3.1</b> Posterior inference for a binomial sampling model</a></li>
<li class="chapter" data-level="3.3.2" data-path="binomial-1.html"><a href="binomial-1.html#conjugacy"><i class="fa fa-check"></i><b>3.3.2</b> Conjugacy</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="binomial-1.html"><a href="binomial-1.html#combining-information"><i class="fa fa-check"></i><b>3.4</b> Combining information</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="binomial-1.html"><a href="binomial-1.html#example-1"><i class="fa fa-check"></i><b>3.4.1</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="binomial-1.html"><a href="binomial-1.html#prediction"><i class="fa fa-check"></i><b>3.5</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="CI.html"><a href="CI.html"><i class="fa fa-check"></i><b>4</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="4.1" data-path="CI.html"><a href="CI.html#confidence-intervals"><i class="fa fa-check"></i><b>4.1</b> Confidence Intervals</a></li>
<li class="chapter" data-level="4.2" data-path="CI.html"><a href="CI.html#how-do-we-compute-intervals"><i class="fa fa-check"></i><b>4.2</b> How do we compute intervals?</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="CI.html"><a href="CI.html#example-2"><i class="fa fa-check"></i><b>4.2.1</b> Example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="poisson-model.html"><a href="poisson-model.html"><i class="fa fa-check"></i><b>5</b> Poisson model</a>
<ul>
<li class="chapter" data-level="5.1" data-path="poisson-model.html"><a href="poisson-model.html#posterior-inference-for-the-poisson-model"><i class="fa fa-check"></i><b>5.1</b> Posterior inference for the Poisson model</a></li>
<li class="chapter" data-level="5.2" data-path="poisson-model.html"><a href="poisson-model.html#posterior-predictive-distribution"><i class="fa fa-check"></i><b>5.2</b> Posterior predictive distribution</a></li>
<li class="chapter" data-level="5.3" data-path="poisson-model.html"><a href="poisson-model.html#example-birth-rates"><i class="fa fa-check"></i><b>5.3</b> Example: Birth rates</a></li>
<li class="chapter" data-level="5.4" data-path="poisson-model.html"><a href="poisson-model.html#explaining-the-parameters-of-the-gamma-distribution"><i class="fa fa-check"></i><b>5.4</b> Explaining the parameters of the gamma distribution</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="monte-carlo.html"><a href="monte-carlo.html"><i class="fa fa-check"></i><b>6</b> Monte Carlo</a>
<ul>
<li class="chapter" data-level="6.1" data-path="monte-carlo.html"><a href="monte-carlo.html#example-birth-rate"><i class="fa fa-check"></i><b>6.1</b> Example: birth rate</a></li>
<li class="chapter" data-level="6.2" data-path="monte-carlo.html"><a href="monte-carlo.html#the-monte-carlo-method"><i class="fa fa-check"></i><b>6.2</b> The Monte Carlo method</a></li>
<li class="chapter" data-level="6.3" data-path="monte-carlo.html"><a href="monte-carlo.html#example-numerical-evaluation"><i class="fa fa-check"></i><b>6.3</b> Example: Numerical evaluation</a></li>
<li class="chapter" data-level="6.4" data-path="monte-carlo.html"><a href="monte-carlo.html#posterior-inference-for-arbitrary-functions"><i class="fa fa-check"></i><b>6.4</b> Posterior inference for arbitrary functions</a></li>
<li class="chapter" data-level="6.5" data-path="monte-carlo.html"><a href="monte-carlo.html#example-log-odds"><i class="fa fa-check"></i><b>6.5</b> Example: Log-odds</a></li>
<li class="chapter" data-level="6.6" data-path="monte-carlo.html"><a href="monte-carlo.html#example-functions-of-two-parameters"><i class="fa fa-check"></i><b>6.6</b> Example: Functions of two parameters</a></li>
<li class="chapter" data-level="6.7" data-path="monte-carlo.html"><a href="monte-carlo.html#how-many-monte-carlo-samples-are-needed"><i class="fa fa-check"></i><b>6.7</b> How many Monte Carlo samples are needed?</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="predictive.html"><a href="predictive.html"><i class="fa fa-check"></i><b>7</b> Predictive</a>
<ul>
<li class="chapter" data-level="7.1" data-path="predictive.html"><a href="predictive.html#sampling-for-predictive-distribution"><i class="fa fa-check"></i><b>7.1</b> Sampling for predictive distribution</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="predictive.html"><a href="predictive.html#example-birth-rate-1"><i class="fa fa-check"></i><b>7.1.1</b> Example: birth rate</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="predictive.html"><a href="predictive.html#example-let-d-tilde-y_1---tilde-y_2"><i class="fa fa-check"></i><b>7.2</b> Example: Let <span class="math inline">\(D = \tilde Y_1 - \tilde Y_2\)</span></a></li>
<li class="chapter" data-level="7.3" data-path="predictive.html"><a href="predictive.html#posterior-predictive-model-checking"><i class="fa fa-check"></i><b>7.3</b> Posterior predictive model checking</a></li>
<li class="chapter" data-level="7.4" data-path="predictive.html"><a href="predictive.html#posterior-predictive-model-checking-1"><i class="fa fa-check"></i><b>7.4</b> Posterior predictive model checking</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="normal-mean.html"><a href="normal-mean.html"><i class="fa fa-check"></i><b>8</b> Normal Mean</a>
<ul>
<li class="chapter" data-level="8.1" data-path="normal-mean.html"><a href="normal-mean.html#example-womens-height"><i class="fa fa-check"></i><b>8.1</b> Example: women’s height</a></li>
<li class="chapter" data-level="8.2" data-path="normal-mean.html"><a href="normal-mean.html#inference-for-the-mean-conditional-on-the-variance"><i class="fa fa-check"></i><b>8.2</b> Inference for the mean, conditional on the variance</a></li>
<li class="chapter" data-level="8.3" data-path="normal-mean.html"><a href="normal-mean.html#prediction-1"><i class="fa fa-check"></i><b>8.3</b> Prediction</a></li>
<li class="chapter" data-level="8.4" data-path="normal-mean.html"><a href="normal-mean.html#example-midge-wing-length"><i class="fa fa-check"></i><b>8.4</b> Example: Midge wing length</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="joint-inference-for-normal-mean-and-variance.html"><a href="joint-inference-for-normal-mean-and-variance.html"><i class="fa fa-check"></i><b>9</b> Joint inference for Normal mean and variance</a>
<ul>
<li class="chapter" data-level="9.1" data-path="joint-inference-for-normal-mean-and-variance.html"><a href="joint-inference-for-normal-mean-and-variance.html#marginal-posterior-of-sigma2"><i class="fa fa-check"></i><b>9.1</b> Marginal posterior of <span class="math inline">\(\sigma^2\)</span></a></li>
<li class="chapter" data-level="9.2" data-path="joint-inference-for-normal-mean-and-variance.html"><a href="joint-inference-for-normal-mean-and-variance.html#example-midge-wing-length-1"><i class="fa fa-check"></i><b>9.2</b> Example: Midge wing length</a></li>
<li class="chapter" data-level="9.3" data-path="joint-inference-for-normal-mean-and-variance.html"><a href="joint-inference-for-normal-mean-and-variance.html#monte-carlo-sampling"><i class="fa fa-check"></i><b>9.3</b> Monte Carlo sampling</a></li>
<li class="chapter" data-level="9.4" data-path="joint-inference-for-normal-mean-and-variance.html"><a href="joint-inference-for-normal-mean-and-variance.html#summary-of-normal-formulas"><i class="fa fa-check"></i><b>9.4</b> Summary of Normal formulas</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="gibbs-sampler.html"><a href="gibbs-sampler.html"><i class="fa fa-check"></i><b>10</b> Gibbs sampler</a>
<ul>
<li class="chapter" data-level="10.1" data-path="gibbs-sampler.html"><a href="gibbs-sampler.html#review-of-conjugate-prior-for-normal-model"><i class="fa fa-check"></i><b>10.1</b> Review of conjugate prior for normal model</a></li>
<li class="chapter" data-level="10.2" data-path="gibbs-sampler.html"><a href="gibbs-sampler.html#a-semiconjugate-prior-distribution"><i class="fa fa-check"></i><b>10.2</b> A semiconjugate prior distribution</a></li>
<li class="chapter" data-level="10.3" data-path="gibbs-sampler.html"><a href="gibbs-sampler.html#gibbs-sampling"><i class="fa fa-check"></i><b>10.3</b> Gibbs sampling</a></li>
<li class="chapter" data-level="10.4" data-path="gibbs-sampler.html"><a href="gibbs-sampler.html#example-midge-wing-length-2"><i class="fa fa-check"></i><b>10.4</b> Example: Midge wing length</a></li>
<li class="chapter" data-level="10.5" data-path="gibbs-sampler.html"><a href="gibbs-sampler.html#discrete-approximation-of-posterior-distribution"><i class="fa fa-check"></i><b>10.5</b> Discrete approximation of posterior distribution</a></li>
<li class="chapter" data-level="10.6" data-path="gibbs-sampler.html"><a href="gibbs-sampler.html#example-3"><i class="fa fa-check"></i><b>10.6</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html"><i class="fa fa-check"></i><b>11</b> MCMC diagnostics</a>
<ul>
<li class="chapter" data-level="11.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#the-gibbs-sampler"><i class="fa fa-check"></i><b>11.1</b> The Gibbs sampler</a></li>
<li class="chapter" data-level="11.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#distinguishing-estimation-from-approximation"><i class="fa fa-check"></i><b>11.2</b> Distinguishing estimation from approximation</a></li>
<li class="chapter" data-level="11.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#introduction-to-mcmc-diagnostics"><i class="fa fa-check"></i><b>11.3</b> Introduction to MCMC diagnostics</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#example-mixture-of-normal-densities"><i class="fa fa-check"></i><b>11.3.1</b> Example: mixture of normal densities</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#discussion"><i class="fa fa-check"></i><b>11.4</b> Discussion</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#how-does-autocorrelationslow-mixing-affect-our-mcmc-approximation"><i class="fa fa-check"></i><b>11.4.1</b> How does autocorrelation(slow mixing) affect our MCMC approximation?</a></li>
<li class="chapter" data-level="11.4.2" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#autocorrelation"><i class="fa fa-check"></i><b>11.4.2</b> Autocorrelation</a></li>
<li class="chapter" data-level="11.4.3" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#sample-autocorrelation-function"><i class="fa fa-check"></i><b>11.4.3</b> Sample autocorrelation function</a></li>
<li class="chapter" data-level="11.4.4" data-path="mcmc-diagnostics.html"><a href="mcmc-diagnostics.html#effective-sample-size"><i class="fa fa-check"></i><b>11.4.4</b> Effective sample size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="multivariate-normal.html"><a href="multivariate-normal.html"><i class="fa fa-check"></i><b>12</b> Multivariate Normal</a>
<ul>
<li class="chapter" data-level="12.1" data-path="multivariate-normal.html"><a href="multivariate-normal.html#example-reading-comprehension"><i class="fa fa-check"></i><b>12.1</b> Example: Reading comprehension</a></li>
<li class="chapter" data-level="12.2" data-path="multivariate-normal.html"><a href="multivariate-normal.html#the-multivariate-normal-density"><i class="fa fa-check"></i><b>12.2</b> The multivariate normal density</a></li>
<li class="chapter" data-level="12.3" data-path="multivariate-normal.html"><a href="multivariate-normal.html#a-semiconjugate-prior-distribution-for-the-mean"><i class="fa fa-check"></i><b>12.3</b> A semiconjugate prior distribution for the mean</a></li>
<li class="chapter" data-level="12.4" data-path="multivariate-normal.html"><a href="multivariate-normal.html#the-inverse-wishart-distribution"><i class="fa fa-check"></i><b>12.4</b> The inverse-Wishart distribution</a></li>
<li class="chapter" data-level="12.5" data-path="multivariate-normal.html"><a href="multivariate-normal.html#full-conditional-distribution-of-the-covariance-matrix"><i class="fa fa-check"></i><b>12.5</b> Full conditional distribution of the covariance matrix</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="group-comparisons.html"><a href="group-comparisons.html"><i class="fa fa-check"></i><b>13</b> Group comparisons</a>
<ul>
<li class="chapter" data-level="13.1" data-path="group-comparisons.html"><a href="group-comparisons.html#comparing-two-groups"><i class="fa fa-check"></i><b>13.1</b> Comparing two groups</a></li>
<li class="chapter" data-level="13.2" data-path="group-comparisons.html"><a href="group-comparisons.html#mathex1"><i class="fa fa-check"></i><b>13.2</b> Example: Math scores data</a></li>
<li class="chapter" data-level="13.3" data-path="group-comparisons.html"><a href="group-comparisons.html#bayesmodel"><i class="fa fa-check"></i><b>13.3</b> A Bayesian model</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="group-comparisons.html"><a href="group-comparisons.html#analysis-of-the-math-scores-data"><i class="fa fa-check"></i><b>13.3.1</b> Analysis of the math scores data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html"><i class="fa fa-check"></i><b>14</b> The hierarchical normal model</a>
<ul>
<li class="chapter" data-level="14.1" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#postinf"><i class="fa fa-check"></i><b>14.1</b> Posterior inference</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#full-conditional-distributions-of-mu-and-tau2"><i class="fa fa-check"></i><b>14.1.1</b> Full conditional distributions of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau^2\)</span></a></li>
<li class="chapter" data-level="14.1.2" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#full-conditional-of-theta_j"><i class="fa fa-check"></i><b>14.1.2</b> Full conditional of <span class="math inline">\(\theta_j\)</span></a></li>
<li class="chapter" data-level="14.1.3" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#full-conditional-of-sigma2"><i class="fa fa-check"></i><b>14.1.3</b> Full conditional of <span class="math inline">\(\sigma^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#mathex2"><i class="fa fa-check"></i><b>14.2</b> Example: Math scores in U.S. public schools</a></li>
<li class="chapter" data-level="14.3" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#posterior-approximation"><i class="fa fa-check"></i><b>14.3</b> Posterior approximation</a></li>
<li class="chapter" data-level="14.4" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#mcmc-diagnostics-1"><i class="fa fa-check"></i><b>14.4</b> MCMC diagnostics</a></li>
<li class="chapter" data-level="14.5" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#shrinkage"><i class="fa fa-check"></i><b>14.5</b> Shrinkage</a></li>
<li class="chapter" data-level="14.6" data-path="the-hierarchical-normal-model.html"><a href="the-hierarchical-normal-model.html#ranking-the-groups"><i class="fa fa-check"></i><b>14.6</b> Ranking the groups</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>15</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="15.1" data-path="linear-regression.html"><a href="linear-regression.html#example-oxygen-uptake"><i class="fa fa-check"></i><b>15.1</b> Example: Oxygen uptake</a></li>
<li class="chapter" data-level="15.2" data-path="linear-regression.html"><a href="linear-regression.html#least-squares-estimation"><i class="fa fa-check"></i><b>15.2</b> Least squares estimation</a></li>
<li class="chapter" data-level="15.3" data-path="linear-regression.html"><a href="linear-regression.html#least-squares-estimation-for-oxygen-uptake-data"><i class="fa fa-check"></i><b>15.3</b> Least squares estimation for oxygen uptake data</a></li>
<li class="chapter" data-level="15.4" data-path="linear-regression.html"><a href="linear-regression.html#bayesian-estimation-for-a-regression-model"><i class="fa fa-check"></i><b>15.4</b> Bayesian estimation for a regression model</a></li>
<li class="chapter" data-level="15.5" data-path="linear-regression.html"><a href="linear-regression.html#unit-information-prior"><i class="fa fa-check"></i><b>15.5</b> Unit information prior</a></li>
<li class="chapter" data-level="15.6" data-path="linear-regression.html"><a href="linear-regression.html#zellners-g-prior"><i class="fa fa-check"></i><b>15.6</b> Zellner’s <span class="math inline">\(g\)</span>-prior</a></li>
<li class="chapter" data-level="15.7" data-path="linear-regression.html"><a href="linear-regression.html#bayesian-analysis-using-invariant-g-prior"><i class="fa fa-check"></i><b>15.7</b> Bayesian analysis using invariant <span class="math inline">\(g\)</span>-prior</a></li>
<li class="chapter" data-level="15.8" data-path="linear-regression.html"><a href="linear-regression.html#bayesian-analysis-using-semiconjugate-prior"><i class="fa fa-check"></i><b>15.8</b> Bayesian analysis using semiconjugate prior</a>
<ul>
<li class="chapter" data-level="15.8.1" data-path="linear-regression.html"><a href="linear-regression.html#prediction-problem"><i class="fa fa-check"></i><b>15.8.1</b> Prediction problem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="model-selection.html"><a href="model-selection.html"><i class="fa fa-check"></i><b>16</b> Model Selection</a>
<ul>
<li class="chapter" data-level="16.1" data-path="model-selection.html"><a href="model-selection.html#review"><i class="fa fa-check"></i><b>16.1</b> Review</a></li>
<li class="chapter" data-level="16.2" data-path="model-selection.html"><a href="model-selection.html#bayesian-model-comparison"><i class="fa fa-check"></i><b>16.2</b> Bayesian model comparison</a></li>
<li class="chapter" data-level="16.3" data-path="model-selection.html"><a href="model-selection.html#example-oxygen-uptake-1"><i class="fa fa-check"></i><b>16.3</b> Example: Oxygen uptake</a></li>
<li class="chapter" data-level="16.4" data-path="model-selection.html"><a href="model-selection.html#gibbs-sampling-and-model-averaging"><i class="fa fa-check"></i><b>16.4</b> Gibbs sampling and model averaging</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html"><i class="fa fa-check"></i><b>17</b> Generalized Linear Models; the Metropolis Algorithm</a>
<ul>
<li class="chapter" data-level="17.1" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html#example-song-sparrow-reproductive-success"><i class="fa fa-check"></i><b>17.1</b> Example: Song sparrow reproductive success</a></li>
<li class="chapter" data-level="17.2" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html#sec:poisson"><i class="fa fa-check"></i><b>17.2</b> Poisson regression</a></li>
<li class="chapter" data-level="17.3" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html#logistic-regression"><i class="fa fa-check"></i><b>17.3</b> Logistic regression</a></li>
<li class="chapter" data-level="17.4" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html#posterior-approximations"><i class="fa fa-check"></i><b>17.4</b> Posterior approximations</a></li>
<li class="chapter" data-level="17.5" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html#the-metropolis-algorithm"><i class="fa fa-check"></i><b>17.5</b> The Metropolis algorithm</a></li>
<li class="chapter" data-level="17.6" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html#example-normal-distribution-with-known-variance"><i class="fa fa-check"></i><b>17.6</b> Example: Normal distribution with known variance</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html#output-of-metropolis-algorithm"><i class="fa fa-check"></i><b>17.6.1</b> Output of Metropolis Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="generalized-linear-models-the-metropolis-algorithm.html"><a href="generalized-linear-models-the-metropolis-algorithm.html#the-metropolis-algorithm-for-poisson-regression-secmetpois"><i class="fa fa-check"></i><b>17.7</b> The Metropolis algorithm for Poisson regression {sec:metpois}</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="metropolis-hastings.html"><a href="metropolis-hastings.html"><i class="fa fa-check"></i><b>18</b> Metropolis-Hastings</a>
<ul>
<li class="chapter" data-level="18.1" data-path="metropolis-hastings.html"><a href="metropolis-hastings.html#why-does-the-metropolis-hastings-algorithm-work"><i class="fa fa-check"></i><b>18.1</b> Why does the Metropolis-Hastings algorithm work?</a></li>
<li class="chapter" data-level="18.2" data-path="metropolis-hastings.html"><a href="metropolis-hastings.html#combining-the-metropolis-and-gibbs-algorithms"><i class="fa fa-check"></i><b>18.2</b> Combining the Metropolis and Gibbs algorithms</a></li>
<li class="chapter" data-level="18.3" data-path="metropolis-hastings.html"><a href="metropolis-hastings.html#example-historical-co_2-and-temperature-data"><i class="fa fa-check"></i><b>18.3</b> Example: Historical CO<span class="math inline">\(_2\)</span> and temperature data</a></li>
<li class="chapter" data-level="18.4" data-path="metropolis-hastings.html"><a href="metropolis-hastings.html#a-regression-model-with-correlated-errors"><i class="fa fa-check"></i><b>18.4</b> A regression model with correlated errors</a></li>
<li class="chapter" data-level="18.5" data-path="metropolis-hastings.html"><a href="metropolis-hastings.html#analysis-of-the-ice-core-data"><i class="fa fa-check"></i><b>18.5</b> Analysis of the ice core data</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><i class="fa fa-check"></i><b>19</b> Linear Mixed-effects Models, aka, Hierarchical Linear Models</a>
<ul>
<li class="chapter" data-level="19.1" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html#hierarchical-model-review"><i class="fa fa-check"></i><b>19.1</b> Hierarchical model review</a></li>
<li class="chapter" data-level="19.2" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html#hierarchical-linear-regression-model-for-math-scores-data"><i class="fa fa-check"></i><b>19.2</b> Hierarchical linear regression model for math scores data</a></li>
<li class="chapter" data-level="19.3" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html#bayesian-hierarchical-linear-regression-model"><i class="fa fa-check"></i><b>19.3</b> Bayesian hierarchical linear regression model</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html#full-conditionals"><i class="fa fa-check"></i><b>19.3.1</b> Full conditionals</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html#bayesian-analysis-of-the-math-scores-data"><i class="fa fa-check"></i><b>19.4</b> Bayesian analysis of the math scores data</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html#mcmc-diagnostics-2"><i class="fa fa-check"></i><b>19.4.1</b> MCMC diagnostics</a></li>
<li class="chapter" data-level="19.4.2" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html#posterior-summaries"><i class="fa fa-check"></i><b>19.4.2</b> Posterior summaries</a></li>
<li class="chapter" data-level="19.4.3" data-path="linear-mixed-effects-models-aka-hierarchical-linear-models.html"><a href="linear-mixed-effects-models-aka-hierarchical-linear-models.html#posterior-predictive-simulation"><i class="fa fa-check"></i><b>19.4.3</b> Posterior predictive simulation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="stan-poisson-regression.html"><a href="stan-poisson-regression.html"><i class="fa fa-check"></i><b>20</b> Stan; Poisson regression</a>
<ul>
<li class="chapter" data-level="20.1" data-path="stan-poisson-regression.html"><a href="stan-poisson-regression.html#intro-to-stan"><i class="fa fa-check"></i><b>20.1</b> Intro to Stan</a></li>
<li class="chapter" data-level="20.2" data-path="stan-poisson-regression.html"><a href="stan-poisson-regression.html#song-sparrows-reproductive-success-example"><i class="fa fa-check"></i><b>20.2</b> Song sparrows reproductive success example</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>21</b> Summary</a>
<ul>
<li class="chapter" data-level="21.1" data-path="summary.html"><a href="summary.html#missing-data-and-imputation-7b"><i class="fa fa-check"></i><b>21.1</b> Missing data and imputation; 7b</a></li>
<li class="chapter" data-level="21.2" data-path="summary.html"><a href="summary.html#generalized-linear-mixed-eﬀects-models-11b"><i class="fa fa-check"></i><b>21.2</b> Generalized linear mixed eﬀects models; 11b</a></li>
<li class="chapter" data-level="21.3" data-path="summary.html"><a href="summary.html#improper-priors"><i class="fa fa-check"></i><b>21.3</b> Improper priors</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian Statistics lecture notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="summary" class="section level1" number="21">
<h1><span class="header-section-number">Lecture 21</span> Summary</h1>
<p><tt>The following notes are mostly transcribed from Neath(0610,2021) lecture.</tt></p>
<p>
 
</p>
<p>We are done in the sense that no new course material will be presented today.</p>
<p>Reminder:</p>
<p>Next Monday is a day of mandatory real-time participation. This will be our “in-class final exam.” It will be interactive and collaborative. My goal for Monday is a learning experience more than final assessment. Attendance is mandatory. Be prepared to re-visit some homework problems and to answer questions posed directly to you ( if you’re chosen by the <span class="math inline">\(\texttt{sample()}\)</span> function in <span class="math inline">\(\texttt{R}\)</span> ).</p>
<p>Given this is the last day and I said no new material let’s spend a few minutes talking about the things we didn’t cover in our course.</p>
<div id="missing-data-and-imputation-7b" class="section level2" number="21.1">
<h2><span class="header-section-number">21.1</span> Missing data and imputation; 7b</h2>
<p>We went over “7a” multivariate normal(MVN) models but we did not go over “7b” which would have been about missing data. Pity because that’s a really cool application of the Gibbs sampler.</p>
<p>Multivariate normal data: <span class="math inline">\(Y_{i,j}\)</span> is response for variable <span class="math inline">\(i\)</span> for unit <span class="math inline">\(j\)</span>. What if we observe <span class="math inline">\(Y_{j} =\)</span> (missing, observed, missing, observed). Suppose <span class="math inline">\(p=4\)</span> (there are 4 variables), and there’s a case in our data set where we have observed <span class="math inline">\(y_2\)</span> and <span class="math inline">\(y_4\)</span> but are missing <span class="math inline">\(y_1\)</span> and <span class="math inline">\(y_3\)</span>. We don’t have to throw that case out! We can use the information that we have. The way we would do this:</p>
<p>Recall for the MVN model we have a Gibbs sampler that works by sampling from the full conditionals <span class="math inline">\(\{~\boldsymbol\theta | \Sigma, \boldsymbol y~\}\)</span> then <span class="math inline">\(\{~\Sigma | \boldsymbol\theta, \boldsymbol y~\}\)</span>. Now write complete data <span class="math inline">\(= \boldsymbol y = (\boldsymbol y_{obs}, \boldsymbol y_{mis}).\)</span></p>
<p>A way to handle missing data is just by adding a step to the Gibbs sampler. We don’t have to solve <span class="math inline">\(\{~\boldsymbol\theta | \boldsymbol\Sigma, y_{obs}~\}\)</span>, <span class="math inline">\(\{~\Sigma |\boldsymbol\theta, \boldsymbol y_{obs}~\}\)</span>. We’ve solved <span class="math inline">\(\{~\boldsymbol\theta | \Sigma, \boldsymbol y~\}\)</span> and <span class="math inline">\(\{~\boldsymbol\Sigma | \boldsymbol{\theta, y}~\}\)</span> already. So add a step to the Gibbs sampler where</p>
<p><span class="math display">\[
\boldsymbol y_{mis}^{(s)} \sim  p( \boldsymbol y_{mis} | \theta^{(s)}, \Sigma^{(s)},\boldsymbol y_{obs})
\]</span></p>
<p>and then use those sampled values for the missing cases for the next update of <span class="math inline">\(\boldsymbol\theta\)</span> and <span class="math inline">\(\boldsymbol\Sigma\)</span>. This is particularly convenient in the MVN model because;</p>
<p>If <span class="math inline">\(\mathbf Y = (\mathbf Y_1, \mathbf Y_2)\)</span> has the MVN normal distribution, <span class="math inline">\(\mathbf Y_1 | \mathbf Y_2 = \boldsymbol y_2\)</span> is MVN and <span class="math inline">\(\mathbf Y_2 | \mathbf Y_1 = \boldsymbol y_1\)</span> is MVN. So the ‘data imputing’ step of the Gibbs sampler is particularly straightforward.</p>
<p>The result is <span class="math inline">\(\boldsymbol\theta^{(s)} , \boldsymbol\Sigma^{(s)}\)</span> are a Gibbs sample from <span class="math inline">\(p(\boldsymbol\theta , \boldsymbol\Sigma | \boldsymbol y_{obs} )\)</span></p>
</div>
<div id="generalized-linear-mixed-eﬀects-models-11b" class="section level2" number="21.2">
<h2><span class="header-section-number">21.2</span> Generalized linear mixed eﬀects models; 11b</h2>
<p>We did not work on “11b,” but we built the foundation for this. In “10a” we talked about Generalized Linear regression Models when the response is something other than normal e.g., Poisson regression and Logistic regression(for binary responses). In 11a we talked about hierarchical regression. Our data are obtained by a two-stage sampling plan and there’s a different regression model (possibly different regression parameters) within the different groups of data. What our “11b” unit would have been about is putting those ideas together. That is, hierarchical regression models for non-normal regression. This is called generalized linear mixed models GLMM.</p>
</div>
<div id="improper-priors" class="section level2" number="21.3">
<h2><span class="header-section-number">21.3</span> Improper priors</h2>
<p>We never did any work with improper priors largely because we were following the text by Hoff and Hoff does not mess with improper priors at all. The Gelman text uses improper priors as a default.</p>
<p>There’s a brief discussion in Hoff page 78. The idea is this; Recall that in the case of the normal distribution we could characterize the conjugate prior for <span class="math inline">\(\sigma^2\)</span> and <span class="math inline">\(\theta\)</span> by</p>
<p><span class="math inline">\(\theta\sim\)</span> Normal<span class="math inline">\((\mu_0, \sigma^2/\kappa_0)\)</span></p>
<p><span class="math inline">\(\sigma^2 \sim\)</span> inverse-gamma<span class="math inline">\((\nu_0/2, ~ \nu_0\sigma^2_0/2)\)</span></p>
<p><span class="math inline">\(\sigma^2_0 =\)</span> prior best guess at <span class="math inline">\(\sigma^2\)</span> and <span class="math inline">\(\nu_0 =\)</span> “sample size on which that’s based.” Also <span class="math inline">\(\mu_0 =\)</span> prior best guess at <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\kappa_0 =\)</span> “sample size on which that’s based.”</p>
<p>What happens if we let <span class="math inline">\(\kappa_0 = 0\)</span> and <span class="math inline">\(\nu_0 = 0\)</span>. This is a logical question: “What if we have no prior information?”</p>
<p>If you look at a chi-square density with degrees of freedom = 0 you get <span class="math inline">\(f(x) = c \times 1 / x\)</span> for <span class="math inline">\(x &gt; 0\)</span>. This is not a probability density because although it’s non-negative for all <span class="math inline">\(x\)</span>, it does not have a finite integral.</p>
<p>Similarly consider a normal distribution and let the prior variance go to infinity. Suppose I said I want my prior density for <span class="math inline">\(\theta\)</span> (the mean of a normal distribution) to be <span class="math inline">\(p(\theta) = 1\)</span> for all <span class="math inline">\(\theta\)</span>, i.e., uniform on <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(+\infty\)</span>. You can’t do that! that’s not a probability distribution because it’s not finite! But if we do it anyway and say <span class="math inline">\(p(\theta | y) = c \times p(\theta) p(y | \theta),\)</span> it still works out. Because of this, this has become a popular way to do Bayesian statistics. To routinely employ noninformative priors and if the parameter space is unbounded they’ll generally be improper priors.</p>
<p>Def: A prior density <span class="math inline">\(p(\theta)\)</span> is proper if <span class="math inline">\(\int { p(\theta) d\theta } &lt; \infty\)</span>. A prior distribution is improper if the prior density <span class="math inline">\(p(\theta)\)</span> has a divergent integral; <span class="math inline">\(\int { p(\theta) d\theta }\)</span> is not finite. However, you can still do this as long as the posterior density <span class="math inline">\(p(\theta | y) = c \times p(\theta) p(y | \theta)\)</span> as is a proper density.</p>
<p>The difficulty is that there’s no guarantee that it is. There are certain models where improper priors lead to proper posteriors. There are other situations where they don’t. It’s not always so easy to know the difference.</p>
<p><strong>Example:</strong></p>
<p>For most Generalized Linear Models, if we take the improper prior distribution <span class="math inline">\(p(\beta) = constant\)</span>, generally the posterior distribution will still be proper and therefore lead to valid conclusions. Let’s look at the Poisson regression example we did where <span class="math inline">\(x =\)</span> age of female bird and <span class="math inline">\(y =\)</span> number of offspring and see if this is the case.</p>
<p>Fitting the model with a normal(0,10) prior.</p>
<div class="sourceCode" id="cb368"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb368-1"><a href="summary.html#cb368-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 52 birds, response is &#39;fledged&#39; -- number of offspring</span></span>
<span id="cb368-2"><a href="summary.html#cb368-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictor variable is age in years (1 to 5)</span></span>
<span id="cb368-3"><a href="summary.html#cb368-3" aria-hidden="true" tabindex="-1"></a>fledged <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">6</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>, </span>
<span id="cb368-4"><a href="summary.html#cb368-4" aria-hidden="true" tabindex="-1"></a>  <span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">2</span>, </span>
<span id="cb368-5"><a href="summary.html#cb368-5" aria-hidden="true" tabindex="-1"></a>  <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb368-6"><a href="summary.html#cb368-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb368-7"><a href="summary.html#cb368-7" aria-hidden="true" tabindex="-1"></a>age <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>, </span>
<span id="cb368-8"><a href="summary.html#cb368-8" aria-hidden="true" tabindex="-1"></a>   <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">5</span>, </span>
<span id="cb368-9"><a href="summary.html#cb368-9" aria-hidden="true" tabindex="-1"></a>   <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">6</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb368-10"><a href="summary.html#cb368-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb368-11"><a href="summary.html#cb368-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rstan)</span>
<span id="cb368-12"><a href="summary.html#cb368-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb368-13"><a href="summary.html#cb368-13" aria-hidden="true" tabindex="-1"></a><span class="co"># description of our model</span></span>
<span id="cb368-14"><a href="summary.html#cb368-14" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> fledged  </span>
<span id="cb368-15"><a href="summary.html#cb368-15" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(y)</span>
<span id="cb368-16"><a href="summary.html#cb368-16" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">1</span>,n), age, age<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb368-17"><a href="summary.html#cb368-17" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(X) <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>n;  </span>
<span id="cb368-18"><a href="summary.html#cb368-18" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(X) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;x1&quot;</span>,<span class="st">&quot;x2&quot;</span>,<span class="st">&quot;x3&quot;</span>)</span>
<span id="cb368-19"><a href="summary.html#cb368-19" aria-hidden="true" tabindex="-1"></a>n           <span class="ot">&lt;-</span> <span class="fu">dim</span>(X)[<span class="dv">1</span>]</span>
<span id="cb368-20"><a href="summary.html#cb368-20" aria-hidden="true" tabindex="-1"></a>p           <span class="ot">&lt;-</span> <span class="fu">dim</span>(X)[<span class="dv">2</span>]</span>
<span id="cb368-21"><a href="summary.html#cb368-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb368-22"><a href="summary.html#cb368-22" aria-hidden="true" tabindex="-1"></a>stan_model <span class="ot">&lt;-</span> <span class="st">&quot;</span></span>
<span id="cb368-23"><a href="summary.html#cb368-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb368-24"><a href="summary.html#cb368-24" aria-hidden="true" tabindex="-1"></a><span class="st">  data{</span></span>
<span id="cb368-25"><a href="summary.html#cb368-25" aria-hidden="true" tabindex="-1"></a><span class="st">   int&lt;lower=0&gt; n; </span></span>
<span id="cb368-26"><a href="summary.html#cb368-26" aria-hidden="true" tabindex="-1"></a><span class="st">   int&lt;lower=0&gt; p;</span></span>
<span id="cb368-27"><a href="summary.html#cb368-27" aria-hidden="true" tabindex="-1"></a><span class="st">   int&lt;lower=0&gt; y[n]; </span></span>
<span id="cb368-28"><a href="summary.html#cb368-28" aria-hidden="true" tabindex="-1"></a><span class="st">   matrix[n,p] X;</span></span>
<span id="cb368-29"><a href="summary.html#cb368-29" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb368-30"><a href="summary.html#cb368-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb368-31"><a href="summary.html#cb368-31" aria-hidden="true" tabindex="-1"></a><span class="st">  parameters{</span></span>
<span id="cb368-32"><a href="summary.html#cb368-32" aria-hidden="true" tabindex="-1"></a><span class="st">   vector[p] beta;</span></span>
<span id="cb368-33"><a href="summary.html#cb368-33" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb368-34"><a href="summary.html#cb368-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb368-35"><a href="summary.html#cb368-35" aria-hidden="true" tabindex="-1"></a><span class="st">  model{</span></span>
<span id="cb368-36"><a href="summary.html#cb368-36" aria-hidden="true" tabindex="-1"></a><span class="st">   beta ~ normal(0, 10);  // prior on beta</span></span>
<span id="cb368-37"><a href="summary.html#cb368-37" aria-hidden="true" tabindex="-1"></a><span class="st">   y ~ poisson_log(X*beta);</span></span>
<span id="cb368-38"><a href="summary.html#cb368-38" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb368-39"><a href="summary.html#cb368-39" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb368-40"><a href="summary.html#cb368-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb368-41"><a href="summary.html#cb368-41" aria-hidden="true" tabindex="-1"></a>data     <span class="ot">&lt;-</span>  <span class="fu">list</span>(<span class="at">n=</span>n, <span class="at">p=</span>p, <span class="at">y=</span>y, <span class="at">X=</span>X);</span>
<span id="cb368-42"><a href="summary.html#cb368-42" aria-hidden="true" tabindex="-1"></a>fit_stan <span class="ot">&lt;-</span> <span class="fu">stan</span>(<span class="at">model_code=</span>stan_model, <span class="at">data=</span>data, </span>
<span id="cb368-43"><a href="summary.html#cb368-43" aria-hidden="true" tabindex="-1"></a> <span class="at">chains=</span><span class="dv">1</span>, <span class="at">iter=</span><span class="dv">5000</span>, <span class="at">warmup=</span><span class="dv">1000</span>, <span class="at">refresh =</span> <span class="dv">0</span>) </span>
<span id="cb368-44"><a href="summary.html#cb368-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb368-45"><a href="summary.html#cb368-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb368-46"><a href="summary.html#cb368-46" aria-hidden="true" tabindex="-1"></a>Results <span class="ot">&lt;-</span> <span class="fu">summary</span>(fit_stan)<span class="sc">$</span>summary[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="dv">4</span><span class="sc">:</span><span class="dv">8</span>];  </span>
<span id="cb368-47"><a href="summary.html#cb368-47" aria-hidden="true" tabindex="-1"></a>Results_normal_prior <span class="ot">&lt;-</span> <span class="fu">round</span>(Results, <span class="dv">2</span>)</span></code></pre></div>
<p>
 
</p>
<p>Let’s fit another Bayesian model, but this time with the prior commented out. Think about what this model says: There is a probability distribution for <span class="math inline">\(\boldsymbol y | \beta,\)</span> there are numeric values of <span class="math inline">\(y\)</span> but there are no values of <span class="math inline">\(\beta\)</span> provided there is no prior distribution specified! What stan does in the absence of a prior distribution is assign a uniform distribution. In this case it’s a uniform distribution on an unbounded space so it’s an improper distribution. What is stan going to do? is it going to crash? Let’s see!</p>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb369-1"><a href="summary.html#cb369-1" aria-hidden="true" tabindex="-1"></a>stan_model2 <span class="ot">&lt;-</span> <span class="st">&quot;</span></span>
<span id="cb369-2"><a href="summary.html#cb369-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb369-3"><a href="summary.html#cb369-3" aria-hidden="true" tabindex="-1"></a><span class="st">  data{</span></span>
<span id="cb369-4"><a href="summary.html#cb369-4" aria-hidden="true" tabindex="-1"></a><span class="st">   int&lt;lower=0&gt; n; </span></span>
<span id="cb369-5"><a href="summary.html#cb369-5" aria-hidden="true" tabindex="-1"></a><span class="st">   int&lt;lower=0&gt; p;</span></span>
<span id="cb369-6"><a href="summary.html#cb369-6" aria-hidden="true" tabindex="-1"></a><span class="st">   int&lt;lower=0&gt; y[n]; </span></span>
<span id="cb369-7"><a href="summary.html#cb369-7" aria-hidden="true" tabindex="-1"></a><span class="st">   matrix[n,p] X;</span></span>
<span id="cb369-8"><a href="summary.html#cb369-8" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb369-9"><a href="summary.html#cb369-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb369-10"><a href="summary.html#cb369-10" aria-hidden="true" tabindex="-1"></a><span class="st">  parameters{</span></span>
<span id="cb369-11"><a href="summary.html#cb369-11" aria-hidden="true" tabindex="-1"></a><span class="st">   vector[p] beta;</span></span>
<span id="cb369-12"><a href="summary.html#cb369-12" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb369-13"><a href="summary.html#cb369-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb369-14"><a href="summary.html#cb369-14" aria-hidden="true" tabindex="-1"></a><span class="st">  model{                 // no prior specified   </span></span>
<span id="cb369-15"><a href="summary.html#cb369-15" aria-hidden="true" tabindex="-1"></a><span class="st">   y ~ poisson_log(X*beta);</span></span>
<span id="cb369-16"><a href="summary.html#cb369-16" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb369-17"><a href="summary.html#cb369-17" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb369-18"><a href="summary.html#cb369-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb369-19"><a href="summary.html#cb369-19" aria-hidden="true" tabindex="-1"></a>data     <span class="ot">&lt;-</span>  <span class="fu">list</span>(<span class="at">n=</span>n, <span class="at">p=</span>p, <span class="at">y=</span>y, <span class="at">X=</span>X);</span>
<span id="cb369-20"><a href="summary.html#cb369-20" aria-hidden="true" tabindex="-1"></a>fit_stan <span class="ot">&lt;-</span> <span class="fu">stan</span>(<span class="at">model_code=</span>stan_model2, <span class="at">data=</span>data, </span>
<span id="cb369-21"><a href="summary.html#cb369-21" aria-hidden="true" tabindex="-1"></a> <span class="at">chains=</span><span class="dv">1</span>, <span class="at">iter=</span><span class="dv">5000</span>, <span class="at">warmup=</span><span class="dv">1000</span>, <span class="at">refresh =</span> <span class="dv">0</span>) </span>
<span id="cb369-22"><a href="summary.html#cb369-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb369-23"><a href="summary.html#cb369-23" aria-hidden="true" tabindex="-1"></a>Results   <span class="ot">&lt;-</span> <span class="fu">summary</span>(fit_stan)<span class="sc">$</span>summary[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="dv">4</span><span class="sc">:</span><span class="dv">8</span>];  </span>
<span id="cb369-24"><a href="summary.html#cb369-24" aria-hidden="true" tabindex="-1"></a>Results_improper_prior <span class="ot">&lt;-</span> <span class="fu">round</span>(Results, <span class="dv">2</span>)</span></code></pre></div>
<p>It didn’t crash.</p>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb370-1"><a href="summary.html#cb370-1" aria-hidden="true" tabindex="-1"></a>Results_improper_prior; Results_normal_prior</span></code></pre></div>
<pre><code>##          2.5%   25%   50%   75% 97.5%
## beta[1] -0.75 -0.06  0.25  0.56  1.16
## beta[2]  0.00  0.47  0.69  0.93  1.46
## beta[3] -0.27 -0.18 -0.14 -0.10 -0.02</code></pre>
<pre><code>##          2.5%   25%   50%   75% 97.5%
## beta[1] -0.70 -0.07  0.23  0.53  1.04
## beta[2]  0.09  0.49  0.71  0.94  1.40
## beta[3] -0.26 -0.18 -0.14 -0.10 -0.04</code></pre>
<p>They are pretty much the same. Using a vague but proper prior like Normal(0 , 100) and using an improper prior lead to identical conclusions. I would argue that the former is safer because this can happen; You have a model where an improper prior does not lead to a proper posterior but MCMC may still work. You’ll get output, but it won’t be meaningful output and you may not even know it.</p>
<p>
 
</p>
<p>Cheers!</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="stan-poisson-regression.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bayesianS21.pdf", "bayesianS21.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
